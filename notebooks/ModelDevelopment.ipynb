{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development using pretrained deeplearning \n",
    "- load dataset\n",
    "- split to training, validation and testing\n",
    "- build pretrained model\n",
    "- train model\n",
    "- evaluate - save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 20:31:42.778433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-05 20:31:42.957969: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-05 20:31:42.957990: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-05 20:31:42.996498: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-05 20:31:43.683028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-05 20:31:43.683098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-05 20:31:43.683104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate, concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from dataset_loader import DatasetLoader\n",
    "dl = DatasetLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>id</th>\n",
       "      <th>ER</th>\n",
       "      <th>CTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.966597</td>\n",
       "      <td>-0.875527</td>\n",
       "      <td>4.228910</td>\n",
       "      <td>1.227844</td>\n",
       "      <td>-5.080250</td>\n",
       "      <td>4.705445</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>3.051015</td>\n",
       "      <td>-0.175810</td>\n",
       "      <td>3.127903</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941808e-31</td>\n",
       "      <td>8.698547e-31</td>\n",
       "      <td>-8.986015e-33</td>\n",
       "      <td>9.681507e-32</td>\n",
       "      <td>9.671273e-32</td>\n",
       "      <td>3.972531e-32</td>\n",
       "      <td>1.305191e-31</td>\n",
       "      <td>ed3071a667a11cc56e88ae0489bfe6aa</td>\n",
       "      <td>0.130945</td>\n",
       "      <td>0.003018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.199574</td>\n",
       "      <td>-0.208893</td>\n",
       "      <td>1.033639</td>\n",
       "      <td>0.443246</td>\n",
       "      <td>-3.230872</td>\n",
       "      <td>2.281240</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>1.537422</td>\n",
       "      <td>-0.728240</td>\n",
       "      <td>-0.246637</td>\n",
       "      <td>...</td>\n",
       "      <td>4.061983e-31</td>\n",
       "      <td>1.054947e-30</td>\n",
       "      <td>9.702705e-32</td>\n",
       "      <td>2.489351e-31</td>\n",
       "      <td>-4.212772e-32</td>\n",
       "      <td>5.718141e-32</td>\n",
       "      <td>5.638410e-33</td>\n",
       "      <td>4799763419d621cd41e7fb8abbcdd45d</td>\n",
       "      <td>0.119002</td>\n",
       "      <td>0.045814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.808152</td>\n",
       "      <td>-1.228349</td>\n",
       "      <td>9.675247</td>\n",
       "      <td>0.373994</td>\n",
       "      <td>-5.530096</td>\n",
       "      <td>4.320427</td>\n",
       "      <td>0.266141</td>\n",
       "      <td>0.484820</td>\n",
       "      <td>3.642968</td>\n",
       "      <td>0.824212</td>\n",
       "      <td>...</td>\n",
       "      <td>2.873673e-31</td>\n",
       "      <td>9.497874e-31</td>\n",
       "      <td>2.269051e-32</td>\n",
       "      <td>3.571017e-32</td>\n",
       "      <td>1.507880e-31</td>\n",
       "      <td>1.479482e-32</td>\n",
       "      <td>6.357522e-32</td>\n",
       "      <td>bf1f7af46eec0e92939a8b3ba51cbacd</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.003419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.296626</td>\n",
       "      <td>-0.031434</td>\n",
       "      <td>1.123966</td>\n",
       "      <td>0.403817</td>\n",
       "      <td>-3.274790</td>\n",
       "      <td>2.300532</td>\n",
       "      <td>0.810319</td>\n",
       "      <td>1.454204</td>\n",
       "      <td>-0.703022</td>\n",
       "      <td>-0.199442</td>\n",
       "      <td>...</td>\n",
       "      <td>4.722566e-31</td>\n",
       "      <td>1.150084e-30</td>\n",
       "      <td>1.459500e-31</td>\n",
       "      <td>2.847329e-31</td>\n",
       "      <td>-9.573101e-32</td>\n",
       "      <td>6.409863e-32</td>\n",
       "      <td>-1.038049e-32</td>\n",
       "      <td>e68e20f592457b875ce29757ab855dfe</td>\n",
       "      <td>0.103688</td>\n",
       "      <td>0.042228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.957764</td>\n",
       "      <td>-0.033983</td>\n",
       "      <td>1.143082</td>\n",
       "      <td>0.301815</td>\n",
       "      <td>-4.055218</td>\n",
       "      <td>2.380942</td>\n",
       "      <td>1.536560</td>\n",
       "      <td>1.216737</td>\n",
       "      <td>-1.139426</td>\n",
       "      <td>-0.577287</td>\n",
       "      <td>...</td>\n",
       "      <td>2.878674e-31</td>\n",
       "      <td>9.302627e-31</td>\n",
       "      <td>6.748744e-33</td>\n",
       "      <td>1.187104e-31</td>\n",
       "      <td>3.532113e-32</td>\n",
       "      <td>-1.003240e-32</td>\n",
       "      <td>5.644234e-32</td>\n",
       "      <td>6a8e741867d4f893afad015b77b52c39</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.031322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  5.966597 -0.875527  4.228910  1.227844 -5.080250  4.705445  0.060572   \n",
       "1  6.199574 -0.208893  1.033639  0.443246 -3.230872  2.281240  0.817452   \n",
       "2  4.808152 -1.228349  9.675247  0.373994 -5.530096  4.320427  0.266141   \n",
       "3  6.296626 -0.031434  1.123966  0.403817 -3.274790  2.300532  0.810319   \n",
       "4  3.957764 -0.033983  1.143082  0.301815 -4.055218  2.380942  1.536560   \n",
       "\n",
       "          7         8         9  ...           249           250  \\\n",
       "0  3.051015 -0.175810  3.127903  ...  2.941808e-31  8.698547e-31   \n",
       "1  1.537422 -0.728240 -0.246637  ...  4.061983e-31  1.054947e-30   \n",
       "2  0.484820  3.642968  0.824212  ...  2.873673e-31  9.497874e-31   \n",
       "3  1.454204 -0.703022 -0.199442  ...  4.722566e-31  1.150084e-30   \n",
       "4  1.216737 -1.139426 -0.577287  ...  2.878674e-31  9.302627e-31   \n",
       "\n",
       "            251           252           253           254           255  \\\n",
       "0 -8.986015e-33  9.681507e-32  9.671273e-32  3.972531e-32  1.305191e-31   \n",
       "1  9.702705e-32  2.489351e-31 -4.212772e-32  5.718141e-32  5.638410e-33   \n",
       "2  2.269051e-32  3.571017e-32  1.507880e-31  1.479482e-32  6.357522e-32   \n",
       "3  1.459500e-31  2.847329e-31 -9.573101e-32  6.409863e-32 -1.038049e-32   \n",
       "4  6.748744e-33  1.187104e-31  3.532113e-32 -1.003240e-32  5.644234e-32   \n",
       "\n",
       "                                 id        ER       CTR  \n",
       "0  ed3071a667a11cc56e88ae0489bfe6aa  0.130945  0.003018  \n",
       "1  4799763419d621cd41e7fb8abbcdd45d  0.119002  0.045814  \n",
       "2  bf1f7af46eec0e92939a8b3ba51cbacd  0.021841  0.003419  \n",
       "3  e68e20f592457b875ce29757ab855dfe  0.103688  0.042228  \n",
       "4  6a8e741867d4f893afad015b77b52c39  0.133475  0.031322  \n",
       "\n",
       "[5 rows x 259 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df = dl.read_numerical_data()\n",
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.003921569, 0.003921569, 0.105882354], [0....</td>\n",
       "      <td>ed3071a667a11cc56e88ae0489bfe6aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>4799763419d621cd41e7fb8abbcdd45d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.13333334, 0.78431374, 1.0], [0.13333334, ...</td>\n",
       "      <td>bf1f7af46eec0e92939a8b3ba51cbacd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>e68e20f592457b875ce29757ab855dfe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>6a8e741867d4f893afad015b77b52c39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img  \\\n",
       "0  [[[0.003921569, 0.003921569, 0.105882354], [0....   \n",
       "1  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...   \n",
       "2  [[[0.13333334, 0.78431374, 1.0], [0.13333334, ...   \n",
       "3  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...   \n",
       "4  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...   \n",
       "\n",
       "                                 id  \n",
       "0  ed3071a667a11cc56e88ae0489bfe6aa  \n",
       "1  4799763419d621cd41e7fb8abbcdd45d  \n",
       "2  bf1f7af46eec0e92939a8b3ba51cbacd  \n",
       "3  e68e20f592457b875ce29757ab855dfe  \n",
       "4  6a8e741867d4f893afad015b77b52c39  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df = dl.read_image_data()\n",
    "img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge the numeric and image dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 259)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>ER</th>\n",
       "      <th>CTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.003921569, 0.003921569, 0.105882354], [0....</td>\n",
       "      <td>5.966597</td>\n",
       "      <td>-0.875527</td>\n",
       "      <td>4.228910</td>\n",
       "      <td>1.227844</td>\n",
       "      <td>-5.080250</td>\n",
       "      <td>4.705445</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>3.051015</td>\n",
       "      <td>-0.175810</td>\n",
       "      <td>...</td>\n",
       "      <td>3.704310e-31</td>\n",
       "      <td>2.941808e-31</td>\n",
       "      <td>8.698547e-31</td>\n",
       "      <td>-8.986015e-33</td>\n",
       "      <td>9.681507e-32</td>\n",
       "      <td>9.671273e-32</td>\n",
       "      <td>3.972531e-32</td>\n",
       "      <td>1.305191e-31</td>\n",
       "      <td>0.130945</td>\n",
       "      <td>0.003018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>6.199574</td>\n",
       "      <td>-0.208893</td>\n",
       "      <td>1.033639</td>\n",
       "      <td>0.443246</td>\n",
       "      <td>-3.230872</td>\n",
       "      <td>2.281240</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>1.537422</td>\n",
       "      <td>-0.728240</td>\n",
       "      <td>...</td>\n",
       "      <td>2.147750e-31</td>\n",
       "      <td>4.061983e-31</td>\n",
       "      <td>1.054947e-30</td>\n",
       "      <td>9.702705e-32</td>\n",
       "      <td>2.489351e-31</td>\n",
       "      <td>-4.212772e-32</td>\n",
       "      <td>5.718141e-32</td>\n",
       "      <td>5.638410e-33</td>\n",
       "      <td>0.119002</td>\n",
       "      <td>0.045814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.13333334, 0.78431374, 1.0], [0.13333334, ...</td>\n",
       "      <td>4.808152</td>\n",
       "      <td>-1.228349</td>\n",
       "      <td>9.675247</td>\n",
       "      <td>0.373994</td>\n",
       "      <td>-5.530096</td>\n",
       "      <td>4.320427</td>\n",
       "      <td>0.266141</td>\n",
       "      <td>0.484820</td>\n",
       "      <td>3.642968</td>\n",
       "      <td>...</td>\n",
       "      <td>3.641521e-31</td>\n",
       "      <td>2.873673e-31</td>\n",
       "      <td>9.497874e-31</td>\n",
       "      <td>2.269051e-32</td>\n",
       "      <td>3.571017e-32</td>\n",
       "      <td>1.507880e-31</td>\n",
       "      <td>1.479482e-32</td>\n",
       "      <td>6.357522e-32</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.003419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>6.296626</td>\n",
       "      <td>-0.031434</td>\n",
       "      <td>1.123966</td>\n",
       "      <td>0.403817</td>\n",
       "      <td>-3.274790</td>\n",
       "      <td>2.300532</td>\n",
       "      <td>0.810319</td>\n",
       "      <td>1.454204</td>\n",
       "      <td>-0.703022</td>\n",
       "      <td>...</td>\n",
       "      <td>2.162406e-31</td>\n",
       "      <td>4.722566e-31</td>\n",
       "      <td>1.150084e-30</td>\n",
       "      <td>1.459500e-31</td>\n",
       "      <td>2.847329e-31</td>\n",
       "      <td>-9.573101e-32</td>\n",
       "      <td>6.409863e-32</td>\n",
       "      <td>-1.038049e-32</td>\n",
       "      <td>0.103688</td>\n",
       "      <td>0.042228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>3.957764</td>\n",
       "      <td>-0.033983</td>\n",
       "      <td>1.143082</td>\n",
       "      <td>0.301815</td>\n",
       "      <td>-4.055218</td>\n",
       "      <td>2.380942</td>\n",
       "      <td>1.536560</td>\n",
       "      <td>1.216737</td>\n",
       "      <td>-1.139426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.704146e-31</td>\n",
       "      <td>2.878674e-31</td>\n",
       "      <td>9.302627e-31</td>\n",
       "      <td>6.748744e-33</td>\n",
       "      <td>1.187104e-31</td>\n",
       "      <td>3.532113e-32</td>\n",
       "      <td>-1.003240e-32</td>\n",
       "      <td>5.644234e-32</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.031322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img         0         1  \\\n",
       "0  [[[0.003921569, 0.003921569, 0.105882354], [0....  5.966597 -0.875527   \n",
       "1  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...  6.199574 -0.208893   \n",
       "2  [[[0.13333334, 0.78431374, 1.0], [0.13333334, ...  4.808152 -1.228349   \n",
       "3  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...  6.296626 -0.031434   \n",
       "4  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...  3.957764 -0.033983   \n",
       "\n",
       "          2         3         4         5         6         7         8  ...  \\\n",
       "0  4.228910  1.227844 -5.080250  4.705445  0.060572  3.051015 -0.175810  ...   \n",
       "1  1.033639  0.443246 -3.230872  2.281240  0.817452  1.537422 -0.728240  ...   \n",
       "2  9.675247  0.373994 -5.530096  4.320427  0.266141  0.484820  3.642968  ...   \n",
       "3  1.123966  0.403817 -3.274790  2.300532  0.810319  1.454204 -0.703022  ...   \n",
       "4  1.143082  0.301815 -4.055218  2.380942  1.536560  1.216737 -1.139426  ...   \n",
       "\n",
       "            248           249           250           251           252  \\\n",
       "0  3.704310e-31  2.941808e-31  8.698547e-31 -8.986015e-33  9.681507e-32   \n",
       "1  2.147750e-31  4.061983e-31  1.054947e-30  9.702705e-32  2.489351e-31   \n",
       "2  3.641521e-31  2.873673e-31  9.497874e-31  2.269051e-32  3.571017e-32   \n",
       "3  2.162406e-31  4.722566e-31  1.150084e-30  1.459500e-31  2.847329e-31   \n",
       "4  2.704146e-31  2.878674e-31  9.302627e-31  6.748744e-33  1.187104e-31   \n",
       "\n",
       "            253           254           255        ER       CTR  \n",
       "0  9.671273e-32  3.972531e-32  1.305191e-31  0.130945  0.003018  \n",
       "1 -4.212772e-32  5.718141e-32  5.638410e-33  0.119002  0.045814  \n",
       "2  1.507880e-31  1.479482e-32  6.357522e-32  0.021841  0.003419  \n",
       "3 -9.573101e-32  6.409863e-32 -1.038049e-32  0.103688  0.042228  \n",
       "4  3.532113e-32 -1.003240e-32  5.644234e-32  0.133475  0.031322  \n",
       "\n",
       "[5 rows x 259 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dl.merge_data_from_multiple_source()\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['CTR']\n",
    "x = dataset.drop(['ER','CTR'],axis=1)\n",
    "img_train_data,img_test_data,numeric_train,numeric_test, y_train, y_test = dl.dataset_preprocess(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(x):\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dense(128, activation=\"relu\")(x) \n",
    "    return x\n",
    "\n",
    "def mode4text_feature(x):\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dense(128, activation=\"relu\")(x) \n",
    "    return x\n",
    "\n",
    "def pretrained_cnn_model(x_inputs):\n",
    "    mobilenetv2 = tf.keras.applications.MobileNetV2(\n",
    "        input_tensor = x_inputs, \n",
    "        weights=\"imagenet\", include_top=False, alpha=0.35) \n",
    "    x = mobilenetv2.get_layer('out_relu').output\n",
    "    x = GlobalAveragePooling2D(name='gap')(x)\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input1_shape, input2_shape,input3_shape):\n",
    "    input1 = Input(shape=input1_shape, name=\"input_image\")\n",
    "    input2 = Input(shape=input2_shape, name=\"input_numerical\") \n",
    "    # input3 = Input(shape=input3_shape, name=\"input_text\")  \n",
    "    \n",
    "    x_image = pretrained_cnn_model(input1)\n",
    "    x_numerical = create_mlp(input2)\n",
    "    # x_text = mode4text_feature(input3)\n",
    "    \n",
    "    x = Concatenate(axis=1)([x_image,x_numerical])\n",
    "    x = Dense(20, activation='relu')(x)\n",
    "    x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[input1,input2],outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 20:32:14.514326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-05 20:32:14.515101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/degaga_wolde/mambaforge/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-05 20:32:14.515144: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/degaga_wolde/mambaforge/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-05 20:32:14.515181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/degaga_wolde/mambaforge/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-05 20:32:14.516934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/degaga_wolde/mambaforge/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-05 20:32:14.516981: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/degaga_wolde/mambaforge/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-05 20:32:14.517015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/degaga_wolde/mambaforge/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-05 20:32:14.517023: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-05 20:32:14.517702: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input1_shape=(256,256,3), input2_shape=(256),input3_shape=(256))\n",
    "opt =  tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-5 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 128, 128, 16  432         ['input_image[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 128, 128, 16  64          ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 128, 128, 16  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 128, 128, 16  144        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 128, 128, 16  64         ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 128, 128, 16  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 128, 128, 8)  128        ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 128, 128, 8)  32         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 128, 128, 48  384         ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 128, 128, 48  192        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 128, 128, 48  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 129, 129, 48  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 64, 64, 48)  432         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 64, 64, 48)  192         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 64, 64, 48)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 64, 64, 8)    384         ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 64, 64, 8)   32          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 64, 64, 48)   384         ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 64, 64, 48)  192         ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 64, 64, 48)   0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 64, 64, 48)  432         ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 64, 64, 48)  192         ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 64, 64, 48)   0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 64, 64, 8)    384         ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 64, 64, 8)   32          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 64, 64, 8)    0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 64, 64, 48)   384         ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 64, 64, 48)  192         ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 64, 64, 48)   0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 65, 65, 48)   0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 32, 32, 48)  432         ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 32, 32, 48)  192         ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 32, 32, 48)   0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 32, 32, 16)   768         ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 32, 32, 16)  64          ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 32, 32, 96)   1536        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 32, 32, 96)  384         ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 32, 32, 96)   0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 32, 32, 96)  864         ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 32, 32, 96)  384         ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 32, 32, 96)   0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 32, 32, 16)   1536        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 32, 32, 16)  64          ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 32, 32, 16)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 32, 32, 96)   1536        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 32, 32, 96)  384         ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 32, 32, 96)   0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 32, 32, 96)  864         ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 32, 32, 96)  384         ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 32, 32, 96)   0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 32, 32, 16)   1536        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 32, 32, 16)  64          ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 32, 32, 16)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 32, 32, 96)   1536        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 32, 32, 96)  384         ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 32, 32, 96)   0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 33, 33, 96)   0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 16, 16, 96)  864         ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 16, 16, 96)  384         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 16, 16, 96)   0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 16, 16, 24)   2304        ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 16, 16, 24)  96          ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 16, 16, 144)  3456        ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 16, 16, 144)  576        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 16, 16, 144)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 16, 16, 144)  1296       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 16, 16, 144)  576        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 16, 16, 144)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 16, 16, 24)   3456        ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 16, 16, 24)  96          ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 16, 16, 24)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 16, 16, 144)  3456        ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 16, 16, 144)  576        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 16, 16, 144)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 16, 16, 144)  1296       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 16, 16, 144)  576        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 16, 16, 144)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 16, 16, 24)   3456        ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 16, 16, 24)  96          ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 16, 16, 24)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 16, 16, 144)  3456        ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 16, 16, 144)  576        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 16, 16, 144)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 16, 16, 144)  1296       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 16, 16, 144)  576        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 16, 16, 144)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 16, 16, 24)   3456        ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 16, 16, 24)  96          ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 16, 16, 24)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 16, 16, 144)  3456        ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 16, 16, 144)  576        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 16, 16, 144)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 16, 16, 144)  1296       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 16, 16, 144)  576        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 16, 16, 144)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 16, 16, 32)   4608        ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 16, 16, 32)  128         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 16, 16, 192)  6144        ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 16, 16, 192)  768        ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 16, 16, 192)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 16, 16, 192)  1728       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 16, 16, 192)  768        ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 16, 16, 192)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 16, 16, 32)   6144        ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 16, 16, 32)  128         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 16, 16, 32)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 16, 16, 192)  6144        ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 16, 16, 192)  768        ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 16, 16, 192)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 16, 16, 192)  1728       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 16, 16, 192)  768        ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 16, 16, 192)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 16, 16, 32)   6144        ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 16, 16, 32)  128         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 16, 16, 32)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 16, 16, 192)  6144        ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 16, 16, 192)  768        ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 16, 16, 192)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 17, 17, 192)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 8, 8, 192)   1728        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 8, 8, 192)   768         ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 8, 8, 192)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 8, 8, 56)     10752       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 8, 8, 56)    224         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 8, 8, 336)    18816       ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 8, 8, 336)   1344        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 8, 8, 336)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 8, 8, 336)   3024        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 8, 8, 336)   1344        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 8, 8, 336)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 8, 8, 56)     18816       ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 8, 8, 56)    224         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 8, 8, 56)     0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 8, 8, 336)    18816       ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 8, 8, 336)   1344        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 8, 8, 336)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 8, 8, 336)   3024        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 8, 8, 336)   1344        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 8, 8, 336)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 8, 8, 56)     18816       ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 8, 8, 56)    224         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 8, 8, 56)     0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 8, 8, 336)    18816       ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 8, 8, 336)   1344        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 8, 8, 336)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 8, 8, 336)   3024        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 8, 8, 336)   1344        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 8, 8, 336)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 8, 8, 112)    37632       ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 8, 8, 112)   448         ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 8, 8, 1280)   143360      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 8, 8, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " input_numerical (InputLayer)   [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 8, 8, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['input_numerical[0][0]']        \n",
      "                                                                                                  \n",
      " gap (GlobalAveragePooling2D)   (None, 1280)         0           ['out_relu[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          131584      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          163968      ['gap[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          65664       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['dense[0][0]',                  \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 20)           5140        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            21          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 842,377\n",
      "Trainable params: 828,297\n",
      "Non-trainable params: 14,080\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 20:32:17.773815: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 342884352 exceeds 10% of free system memory.\n",
      "2022-11-05 20:32:17.892569: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 685768704 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 14s 199ms/step - loss: 6923988.0000\n",
      "Epoch 2/150\n",
      "55/55 [==============================] - 11s 203ms/step - loss: 2673344.2500\n",
      "Epoch 3/150\n",
      "55/55 [==============================] - 11s 197ms/step - loss: 4133933.0000\n",
      "Epoch 4/150\n",
      "55/55 [==============================] - 11s 201ms/step - loss: 3435002.2500\n",
      "Epoch 5/150\n",
      "55/55 [==============================] - 11s 202ms/step - loss: 2668813.0000\n",
      "Epoch 6/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 2056976.0000\n",
      "Epoch 7/150\n",
      "55/55 [==============================] - 11s 204ms/step - loss: 3841422.0000\n",
      "Epoch 8/150\n",
      "55/55 [==============================] - 11s 196ms/step - loss: 2243558.0000\n",
      "Epoch 9/150\n",
      "55/55 [==============================] - 10s 191ms/step - loss: 2539890.5000\n",
      "Epoch 10/150\n",
      "55/55 [==============================] - 11s 195ms/step - loss: 2177489.2500\n",
      "Epoch 11/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 2500026.2500\n",
      "Epoch 12/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 2900281.2500\n",
      "Epoch 13/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 2840546.7500\n",
      "Epoch 14/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 2204470.5000\n",
      "Epoch 15/150\n",
      "55/55 [==============================] - 11s 209ms/step - loss: 2917082.7500\n",
      "Epoch 16/150\n",
      "55/55 [==============================] - 11s 202ms/step - loss: 2568613.5000\n",
      "Epoch 17/150\n",
      "55/55 [==============================] - 12s 216ms/step - loss: 2317899.5000\n",
      "Epoch 18/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 2491818.0000\n",
      "Epoch 19/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 2088298.2500\n",
      "Epoch 20/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 2328689.5000\n",
      "Epoch 21/150\n",
      "55/55 [==============================] - 11s 195ms/step - loss: 3551403.2500\n",
      "Epoch 22/150\n",
      "55/55 [==============================] - 11s 195ms/step - loss: 2081320.6250\n",
      "Epoch 23/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 2068782.5000\n",
      "Epoch 24/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 2100087.2500\n",
      "Epoch 25/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 2771674.7500\n",
      "Epoch 26/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 2601872.5000\n",
      "Epoch 27/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 3098961.5000\n",
      "Epoch 28/150\n",
      "55/55 [==============================] - 10s 191ms/step - loss: 1707728.6250\n",
      "Epoch 29/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 1910339.8750\n",
      "Epoch 30/150\n",
      "55/55 [==============================] - 11s 202ms/step - loss: 2559151.7500\n",
      "Epoch 31/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 1437464.5000\n",
      "Epoch 32/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 1569337.3750\n",
      "Epoch 33/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 3257041.2500\n",
      "Epoch 34/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 2354585.7500\n",
      "Epoch 35/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 1733768.7500\n",
      "Epoch 36/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 1914590.5000\n",
      "Epoch 37/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 2449794.2500\n",
      "Epoch 38/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 1382035.2500\n",
      "Epoch 39/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 1545547.0000\n",
      "Epoch 40/150\n",
      "55/55 [==============================] - 11s 202ms/step - loss: 1587995.0000\n",
      "Epoch 41/150\n",
      "55/55 [==============================] - 11s 195ms/step - loss: 2010850.3750\n",
      "Epoch 42/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 1410284.1250\n",
      "Epoch 43/150\n",
      "55/55 [==============================] - 10s 189ms/step - loss: 1797886.0000\n",
      "Epoch 44/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 1797083.8750\n",
      "Epoch 45/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 1924186.0000\n",
      "Epoch 46/150\n",
      "55/55 [==============================] - 11s 207ms/step - loss: 1376112.6250\n",
      "Epoch 47/150\n",
      "55/55 [==============================] - 11s 196ms/step - loss: 906907.1250\n",
      "Epoch 48/150\n",
      "55/55 [==============================] - 11s 196ms/step - loss: 1139102.8750\n",
      "Epoch 49/150\n",
      "55/55 [==============================] - 11s 202ms/step - loss: 2033912.7500\n",
      "Epoch 50/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 1559915.2500\n",
      "Epoch 51/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 1376655.8750\n",
      "Epoch 52/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 1623626.3750\n",
      "Epoch 53/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 746028.9375\n",
      "Epoch 54/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 1730785.8750\n",
      "Epoch 55/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 1012196.6875\n",
      "Epoch 56/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 615632.0625\n",
      "Epoch 57/150\n",
      "55/55 [==============================] - 11s 205ms/step - loss: 819099.0625\n",
      "Epoch 58/150\n",
      "55/55 [==============================] - 12s 222ms/step - loss: 632165.8750\n",
      "Epoch 59/150\n",
      "55/55 [==============================] - 11s 206ms/step - loss: 1516665.5000\n",
      "Epoch 60/150\n",
      "55/55 [==============================] - 11s 207ms/step - loss: 660543.7500\n",
      "Epoch 61/150\n",
      "55/55 [==============================] - 11s 208ms/step - loss: 918370.5000\n",
      "Epoch 62/150\n",
      "55/55 [==============================] - 11s 209ms/step - loss: 926627.0625\n",
      "Epoch 63/150\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 1034526.6875\n",
      "Epoch 64/150\n",
      "55/55 [==============================] - 11s 208ms/step - loss: 539620.5000\n",
      "Epoch 65/150\n",
      "55/55 [==============================] - 11s 207ms/step - loss: 834807.6875\n",
      "Epoch 66/150\n",
      "55/55 [==============================] - 12s 209ms/step - loss: 618937.3125\n",
      "Epoch 67/150\n",
      "55/55 [==============================] - 11s 207ms/step - loss: 849799.2500\n",
      "Epoch 68/150\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 909445.5625\n",
      "Epoch 69/150\n",
      "55/55 [==============================] - 11s 202ms/step - loss: 1203961.8750\n",
      "Epoch 70/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 542763.1250\n",
      "Epoch 71/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 900063.0000\n",
      "Epoch 72/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 336918.0312\n",
      "Epoch 73/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 632525.3125\n",
      "Epoch 74/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 667506.5625\n",
      "Epoch 75/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 430796.6875\n",
      "Epoch 76/150\n",
      "55/55 [==============================] - 10s 191ms/step - loss: 518589.2500\n",
      "Epoch 77/150\n",
      "55/55 [==============================] - 10s 191ms/step - loss: 560636.0000\n",
      "Epoch 78/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 713808.8125\n",
      "Epoch 79/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 955002.0000\n",
      "Epoch 80/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 960927.9375\n",
      "Epoch 81/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 418307.1875\n",
      "Epoch 82/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 699370.0625\n",
      "Epoch 83/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 377659.8750\n",
      "Epoch 84/150\n",
      "55/55 [==============================] - 11s 199ms/step - loss: 594333.8125\n",
      "Epoch 85/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 233833.2812\n",
      "Epoch 86/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 369678.3750\n",
      "Epoch 87/150\n",
      "55/55 [==============================] - 10s 191ms/step - loss: 846966.3750\n",
      "Epoch 88/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 404908.2812\n",
      "Epoch 89/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 325082.8125\n",
      "Epoch 90/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 437224.4688\n",
      "Epoch 91/150\n",
      "55/55 [==============================] - 10s 189ms/step - loss: 348704.1250\n",
      "Epoch 92/150\n",
      "55/55 [==============================] - 10s 189ms/step - loss: 314651.7188\n",
      "Epoch 93/150\n",
      "55/55 [==============================] - 11s 205ms/step - loss: 365898.6875\n",
      "Epoch 94/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 308096.6875\n",
      "Epoch 95/150\n",
      "55/55 [==============================] - 11s 195ms/step - loss: 276882.8125\n",
      "Epoch 96/150\n",
      "55/55 [==============================] - 11s 197ms/step - loss: 291112.9688\n",
      "Epoch 97/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 473603.3125\n",
      "Epoch 98/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 143080.7969\n",
      "Epoch 99/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 178773.3750\n",
      "Epoch 100/150\n",
      "55/55 [==============================] - 11s 201ms/step - loss: 253549.2500\n",
      "Epoch 101/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 258443.6406\n",
      "Epoch 102/150\n",
      "55/55 [==============================] - 11s 197ms/step - loss: 412734.5938\n",
      "Epoch 103/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 443831.8750\n",
      "Epoch 104/150\n",
      "55/55 [==============================] - 10s 188ms/step - loss: 129260.9609\n",
      "Epoch 105/150\n",
      "55/55 [==============================] - 10s 189ms/step - loss: 62067.2266\n",
      "Epoch 106/150\n",
      "55/55 [==============================] - 10s 189ms/step - loss: 167875.9375\n",
      "Epoch 107/150\n",
      "55/55 [==============================] - 11s 197ms/step - loss: 219254.2031\n",
      "Epoch 108/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 87132.5234\n",
      "Epoch 109/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 66745.0938\n",
      "Epoch 110/150\n",
      "55/55 [==============================] - 11s 202ms/step - loss: 68098.1484\n",
      "Epoch 111/150\n",
      "55/55 [==============================] - 11s 199ms/step - loss: 131364.5000\n",
      "Epoch 112/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 38368.4375\n",
      "Epoch 113/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 118204.6719\n",
      "Epoch 114/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 120134.0000\n",
      "Epoch 115/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 28393.3027\n",
      "Epoch 116/150\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 123789.1719\n",
      "Epoch 117/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 127375.6484\n",
      "Epoch 118/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 98164.4297\n",
      "Epoch 119/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 141059.9062\n",
      "Epoch 120/150\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 89842.2656\n",
      "Epoch 121/150\n",
      "55/55 [==============================] - 12s 223ms/step - loss: 111451.2656\n",
      "Epoch 122/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 133293.7656\n",
      "Epoch 123/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 102368.9062\n",
      "Epoch 124/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 28860.7852\n",
      "Epoch 125/150\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 87173.5938\n",
      "Epoch 126/150\n",
      "55/55 [==============================] - 11s 197ms/step - loss: 53808.3203\n",
      "Epoch 127/150\n",
      "55/55 [==============================] - 11s 208ms/step - loss: 60798.1289\n",
      "Epoch 128/150\n",
      "55/55 [==============================] - 12s 224ms/step - loss: 40876.4141\n",
      "Epoch 129/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 27036.1035\n",
      "Epoch 130/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 27272.7090\n",
      "Epoch 131/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 11871.0508\n",
      "Epoch 132/150\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 623.4856\n",
      "Epoch 133/150\n",
      "55/55 [==============================] - 11s 198ms/step - loss: 977.6570\n",
      "Epoch 134/150\n",
      "55/55 [==============================] - 10s 191ms/step - loss: 586.1767\n",
      "Epoch 135/150\n",
      "55/55 [==============================] - 11s 196ms/step - loss: 127185.4609\n",
      "Epoch 136/150\n",
      "55/55 [==============================] - 11s 207ms/step - loss: 521.4000\n",
      "Epoch 137/150\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 428.1913\n",
      "Epoch 138/150\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 34584.4609\n",
      "Epoch 139/150\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 9481.3330\n",
      "Epoch 140/150\n",
      "55/55 [==============================] - 11s 206ms/step - loss: 7441.6401\n",
      "Epoch 141/150\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 23434.0801\n",
      "Epoch 142/150\n",
      "55/55 [==============================] - 12s 209ms/step - loss: 13092.3340\n",
      "Epoch 143/150\n",
      "55/55 [==============================] - 12s 218ms/step - loss: 47920.5859\n",
      "Epoch 144/150\n",
      "55/55 [==============================] - 11s 209ms/step - loss: 734.2474\n",
      "Epoch 145/150\n",
      "55/55 [==============================] - 12s 219ms/step - loss: 368.7578\n",
      "Epoch 146/150\n",
      "55/55 [==============================] - 11s 199ms/step - loss: 1132.7070\n",
      "Epoch 147/150\n",
      "55/55 [==============================] - 11s 197ms/step - loss: 450.3971\n",
      "Epoch 148/150\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 409.4720\n",
      "Epoch 149/150\n",
      "55/55 [==============================] - 10s 191ms/step - loss: 316.9217\n",
      "Epoch 150/150\n",
      "55/55 [==============================] - 11s 201ms/step - loss: 72339.9062\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=[\n",
    "        tf.cast(img_train_data,tf.float64),\n",
    "        tf.cast(numeric_train,tf.float64)\n",
    "        ],\n",
    "    y = tf.cast(y_train, tf.float64),\n",
    "    epochs=500,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2/ElEQVR4nO3dd5hTVfoH8G/KJJnee4Ghd6RLUVBARUVd2y6Lin1VXAt292ffFcta1rLIuoq6q4INGyprQRCkF+lDh6FML5maTJLz+yO5Nzd1MsMwNzPz/TzPPM7c3Nycm0Hy8p73vEcjhBAgIiIiCkNatQdAREREFAgDFSIiIgpbDFSIiIgobDFQISIiorDFQIWIiIjCFgMVIiIiClsMVIiIiChsMVAhIiKisMVAhYiIiMIWAxUilRw6dAgajQbvvPNOi5/7888/Q6PR4Oeff27zcRERhRMGKkRERBS2GKgQERFR2GKgQkR0CjU2NsLhcKj2+g6HA42NjX4fq6urO+nr19fXn/Q1iIJhoEJd1uOPPw6NRoM9e/bgqquuQnx8PFJTU/HII49ACIHCwkJcfPHFiIuLQ0ZGBl544QWfa5SUlOCGG25Aeno6TCYThg4dinfffdfnvKqqKlx77bWIj49HQkICZs2ahaqqKr/j2r17Ny6//HIkJSXBZDJh5MiR+PLLL1W7R4vFgsceewy9evWC0WhEbm4u7r//flgsFo/zFixYgLPPPhtpaWkwGo0YMGAA5s2b53O97t2748ILL8TKlSsxevRomEwm9OjRA++9915I97Rw4UKMGDECsbGxiIuLw+DBg/GPf/zD45wdO3bg7LPPRmRkJHJycvDXv/4Vb7/9NjQaDQ4dOiSfp9Fo8Pjjj/sd47XXXiv/XFFRgXvvvReDBw9GTEwM4uLiMG3aNPz2228ez5NqhxYuXIj/+7//Q3Z2NqKiomA2mwEAa9euxXnnnYf4+HhERUVh4sSJWLVqVUj3HervQaPR4Pbbb8f777+PgQMHwmg04rvvvsM777wDjUaD5cuX47bbbkNaWhpycnLk5/3zn/+Uz8/KysLs2bN9/oxOmjQJgwYNwsaNG3HmmWciKioKDz/8cEjjJ2otvdoDIFLb73//e/Tv3x/PPPMMlixZgr/+9a9ISkrC/PnzcfbZZ+PZZ5/F+++/j3vvvRejRo3CmWeeCQBoaGjApEmTsG/fPtx+++3Iz8/Hxx9/jGuvvRZVVVW48847AQBCCFx88cVYuXIlbrnlFvTv3x+LFy/GrFmzfMayY8cOjB8/HtnZ2XjwwQcRHR2Njz76CJdccgk+/fRT/O53v2vXe3Q4HLjooouwcuVK3Hzzzejfvz+2bduGl156CXv27MHnn38uv8a8efMwcOBAXHTRRdDr9fjqq69w2223weFwYPbs2R7j2bdvHy6//HLccMMNmDVrFt5++21ce+21GDFiBAYOHBjwPr7//nvMmDEDkydPxrPPPgsA2LVrF1atWiW/30VFRTjrrLNgs9nk9/Bf//oXIiMjW/XeAcCBAwfw+eef44orrkB+fj6Ki4sxf/58TJw4ETt37kRWVpbH+U899RQMBgPuvfdeWCwWGAwG/PTTT5g2bRpGjBiBxx57DFqtVg7ufvnlF4wePTrg67fk9wAAP/30Ez766CPcfvvtSElJQffu3bFlyxYAwG233YbU1FQ8+uijckbl8ccfxxNPPIEpU6bg1ltvRUFBAebNm4f169dj1apViIiIkK9dXl6OadOm4Q9/+AOuuuoqpKent/p9JQqJIOqiHnvsMQFA3HzzzfIxm80mcnJyhEajEc8884x8vLKyUkRGRopZs2bJx15++WUBQPz3v/+Vj1mtVjF27FgRExMjzGazEEKIzz//XAAQzz33nMfrnHHGGQKAWLBggXx88uTJYvDgwaKxsVE+5nA4xLhx40Tv3r3lY8uWLRMAxLJly07pPf7nP/8RWq1W/PLLLx7XfeONNwQAsWrVKvlYfX29z+ufe+65okePHh7HunXrJgCIFStWyMdKSkqE0WgU99xzT9D7ufPOO0VcXJyw2WwBz7nrrrsEALF27VqP68fHxwsA4uDBg/JxAOKxxx7zuUa3bt083ofGxkZht9s9zjl48KAwGo3iySeflI9Jv5cePXp4vB8Oh0P07t1bnHvuucLhcMjH6+vrRX5+vpg6dWrQ+27J7wGA0Gq1YseOHR7nLliwQAAQEyZM8Hj/SkpKhMFgEOecc47HPb722msCgHj77bflYxMnThQAxBtvvBF0vERtiVM/1OXdeOON8vc6nQ4jR46EEAI33HCDfDwhIQF9+/bFgQMH5GPffPMNMjIyMGPGDPlYREQE7rjjDtTW1mL58uXyeXq9HrfeeqvH6/z5z3/2GEdFRQV++uknXHnllaipqUFZWRnKyspQXl6Oc889F3v37sWxY8fa9R4//vhj9O/fH/369ZPHU1ZWhrPPPhsAsGzZMvlcZcaiuroaZWVlmDhxIg4cOIDq6mqP8QwYMABnnHGG/HNqaqrPa/uTkJCAuro6fP/99wHP+eabb3D66ad7ZChSU1Mxc+bMoNcOxmg0Qqt1/nVpt9tRXl6OmJgY9O3bF5s2bfI5f9asWR7vx5YtW7B371788Y9/RHl5ufw+1tXVYfLkyVixYkXQOpaW/B4AYOLEiRgwYIDfa910003Q6XTyzz/88AOsVivuuusu+R6l8+Li4rBkyRKf9+K6664LOFaittZpApUVK1Zg+vTpyMrKgkaj8UmFhkIIgb///e/o06cPjEYjsrOz8be//a3tB0thJS8vz+Pn+Ph4mEwmpKSk+ByvrKyUfz58+DB69+7t8Zc7APTv319+XPpvZmYmYmJiPM7r27evx8/79u2DEAKPPPIIUlNTPb4ee+wxAM6amPa8x71792LHjh0+4+nTp4/PeFatWoUpU6YgOjoaCQkJSE1NlesXvAMV7/EAQGJiosdr+3PbbbehT58+mDZtGnJycnD99dfju+++8zhH+r14836/W8LhcOCll15C7969YTQakZKSgtTUVGzdutXn3gAgPz/f4+e9e/cCcAYw3u/lv//9b1gsFr/XUT4/1N+Dv9cP9pj059T7/TEYDOjRo4f8uCQ7OxsGgyHg9YnaWqepUamrq8PQoUNx/fXX49JLL23VNe68807873//w9///ncMHjwYFRUVqKioaOORUrhR/usy2DHAGcyeKtK/qO+9916ce+65fs/p1atXq67d2nt0OBwYPHgwXnzxRb/n5ubmAgD279+PyZMno1+/fnjxxReRm5sLg8GAb775Bi+99JJPtqC1729aWhq2bNmCpUuX4ttvv8W3336LBQsW4JprrvFbxNxadrvd4+enn34ajzzyCK6//no89dRTSEpKglarxV133eU3E+JdDyOd8/zzz+O0007z+5regaz380P5PQR6/VAfC8XJPp+opTpNoDJt2jRMmzYt4OMWiwV/+ctf8OGHH6KqqgqDBg3Cs88+i0mTJgFwFuTNmzcP27dvl/9lEexfJUTdunXD1q1b4XA4PLIqu3fvlh+X/vvjjz+itrbW48OooKDA43o9evQA4Jw+mjJlyqkefkh69uyJ3377DZMnT4ZGowl43ldffQWLxYIvv/zSI1viPSXRFgwGA6ZPn47p06fD4XDgtttuw/z58/HII4+gV69e6Natm5zBUPJ+vwFnFsd7ZYvVasWJEyc8jn3yySc466yz8NZbb3kcr6qq8slK+dOzZ08AQFxcXKt+t6H+HlpD+nNaUFAg/xkEnO/DwYMHw+bPInVdnWbqpzm33347Vq9ejYULF2Lr1q244oorcN5558l/oX311Vfo0aMHvv76a+Tn56N79+648cYbmVGhgM4//3wUFRVh0aJF8jGbzYZXX30VMTExmDhxonyezWbzWKprt9vx6quvelwvLS0NkyZNwvz5830+KAGgtLT0FN1JYFdeeSWOHTuGN9980+exhoYGedWIlCFRZkSqq6uxYMGCNh1PeXm5x89arRZDhgwBAHmZ7vnnn481a9Zg3bp18nmlpaV4//33fa7Xs2dPrFixwuPYv/71L5+Mik6n88n2fPzxxyHXDI0YMQI9e/bE3//+d9TW1vo83tzvNtTfQ2tMmTIFBoMBr7zyisc9vvXWW6iursYFF1zQ6msTtYVOk1EJ5siRI1iwYAGOHDkiLyO899578d1332HBggV4+umnceDAARw+fBgff/wx3nvvPdjtdtx99924/PLL8dNPP6l8BxSObr75ZsyfPx/XXnstNm7ciO7du+OTTz7BqlWr8PLLLyM2NhYAMH36dIwfPx4PPvggDh06hAEDBuCzzz7zW5Pw+uuvY8KECRg8eDBuuukm9OjRA8XFxVi9ejWOHj3q07fjVLv66qvx0Ucf4ZZbbsGyZcswfvx42O127N69Gx999BGWLl2KkSNH4pxzzpEzHX/6059QW1uLN998E2lpaX6DrtaS/vFw9tlnIycnB4cPH8arr76K0047Ta4Nuv/++/Gf//wH5513Hu688055ebKUAfO+3i233ILLLrsMU6dOxW+//YalS5f6ZEkuvPBCPPnkk7juuuswbtw4bNu2De+//75HBiIYrVaLf//735g2bRoGDhyI6667DtnZ2Th27BiWLVuGuLg4fPXVVwGfH+rvoTVSU1Px0EMP4YknnsB5552Hiy66CAUFBfjnP/+JUaNG4aqrrmrVdYnajFrLjU4lAGLx4sXyz19//bUAIKKjoz2+9Hq9uPLKK4UQQtx0000CgCgoKJCft3HjRgFA7N69u71vgdqBtHS3tLTU4/isWbNEdHS0z/kTJ04UAwcO9DhWXFwsrrvuOpGSkiIMBoMYPHiwx3JjSXl5ubj66qtFXFyciI+PF1dffbXYvHmzz/JkIYTYv3+/uOaaa0RGRoaIiIgQ2dnZ4sILLxSffPKJfE5LlyefzD1arVbx7LPPioEDBwqj0SgSExPFiBEjxBNPPCGqq6vl87788ksxZMgQYTKZRPfu3cWzzz4r3n77bZ8lwd26dRMXXHCB39eeOHFi0Pv55JNPxDnnnCPS0tKEwWAQeXl54k9/+pM4ceKEx3lbt24VEydOFCaTSWRnZ4unnnpKvPXWWz5jsdvt4oEHHhApKSkiKipKnHvuuWLfvn1+lyffc889IjMzU0RGRorx48eL1atX+4xZ+r18/PHHfse/efNmcemll4rk5GRhNBpFt27dxJVXXil+/PHHoPctROi/BwBi9uzZPs+XlievX7/e7/Vfe+010a9fPxERESHS09PFrbfeKiorKz3O8ffng+hU0whxCqsDVaLRaLB48WJccsklAIBFixZh5syZ2LFjh08RX0xMDDIyMvDYY4/h6aefRlNTk/xYQ0MDoqKi8L///Q9Tp05tz1sgojb2zjvv4LrrrsPBgwfRvXt3tYdDRCHqElM/w4YNg91uR0lJiUfvBqXx48fDZrNh//79cuHbnj17ALiLzYiIiKh9dZpApba2Fvv27ZN/PnjwILZs2YKkpCT06dMHM2fOxDXXXIMXXngBw4YNQ2lpKX788UcMGTIEF1xwAaZMmYLhw4fj+uuvx8svvyy3/Z46darcq4CIiIjaV6dZ9bNhwwYMGzYMw4YNAwDMmTMHw4YNw6OPPgoAcq+Fe+65B3379sUll1yC9evXy0sptVotvvrqK6SkpODMM8/EBRdcgP79+2PhwoWq3RMREVFX1ylrVIiIiKhz6DQZFSIiIup8GKgQERFR2OrQxbQOhwPHjx9HbGxsm7eVJiIiolNDCIGamhpkZWX5bOzqrUMHKsePH/fZjIuIiIg6hsLCQuTk5AQ9p0MHKlKL8sLCQsTFxak8GiIiIgqF2WxGbm6u/DkeTIcOVKTpnri4OAYqREREHUwoZRsspiUiIqKwxUCFiIiIwhYDFSIiIgpbDFSIiIgobDFQISIiorDFQIWIiIjClqqBSvfu3aHRaHy+Zs+ereawiIiIKEyo2kdl/fr1sNvt8s/bt2/H1KlTccUVV6g4KiIiIgoXqgYqqampHj8/88wz6NmzJyZOnKjSiIiIiCichE1nWqvViv/+97+YM2dOwE51FosFFotF/tlsNrfX8IiIiEgFYVNM+/nnn6OqqgrXXnttwHPmzp2L+Ph4+YsbEhIREXVuGiGEUHsQAHDuuefCYDDgq6++CniOv4xKbm4uqqurudcPERFRB2E2mxEfHx/S53dYTP0cPnwYP/zwAz777LOg5xmNRhiNxlM+nnqrDRV1Vhj0WqTFmk756xEREZF/YTH1s2DBAqSlpeGCCy5QeygAgO93FmPCs8swZ9Fvag+FiIioS1M9UHE4HFiwYAFmzZoFvT4sEjzQuop5bQ6HyiMhIiLq2lQPVH744QccOXIE119/vdpDkem1zkDF7giL8h0iIqIuS/UUxjnnnIMwqeeV6RioEBERhQXVMyrhSK9joEJERBQOGKj44a5RYaBCRESkJgYqfui1zreFGRUiIiJ1MVDxgzUqRERE4YGBih+sUSEiIgoPDFT8YI0KERFReGCg4gf7qBAREYUHBip+sEaFiIgoPDBQ8UOqUeHUDxERkboYqPih00gZFe71Q0REpCYGKn5IUz/MqBAREamLgYofUsM3BwMVIiIiVTFQ8UPHGhUiIqKwwEDFDy5PJiIiCg8MVPxgwzciIqLwwEDFDymjArBOhYiISE0MVPyQalQAZlWIiIjUxEDFD2VGhXUqRERE6mGg4odUowIANjZ9IyIiUg0DFT88a1RUHAgREVEXx0DFD52WGRUiIqJwwEDFD41Gwx2UiYiIwgADlQB07KVCRESkOgYqATCjQkREpD4GKgGwjT4REZH6GKgEwI0JiYiI1MdAJQCpRoUZFSIiIvUwUAlAqlHh8mQiIiL1MFAJQKpRYZxCRESkHgYqAbhrVBipEBERqYWBSgCsUSEiIlIfA5UA3DUqDFSIiIjUwkAlAL3W+dY4GKgQERGphoFKAMyoEBERqY+BSgBsoU9ERKQ+BioBMKNCRESkPgYqAXCvHyIiIvWpHqgcO3YMV111FZKTkxEZGYnBgwdjw4YNag+LUz9ERERhQK/mi1dWVmL8+PE466yz8O233yI1NRV79+5FYmKimsMCwBb6RERE4UDVQOXZZ59Fbm4uFixYIB/Lz89XcURuzKgQERGpT9Wpny+//BIjR47EFVdcgbS0NAwbNgxvvvmmmkOSsUaFiIhIfaoGKgcOHMC8efPQu3dvLF26FLfeeivuuOMOvPvuu37Pt1gsMJvNHl+nis7V8I2BChERkXpUnfpxOBwYOXIknn76aQDAsGHDsH37drzxxhuYNWuWz/lz587FE0880S5j07lCOC5PJiIiUo+qGZXMzEwMGDDA41j//v1x5MgRv+c/9NBDqK6ulr8KCwtP2dj0zKgQERGpTtWMyvjx41FQUOBxbM+ePejWrZvf841GI4xGY3sMjcW0REREYUDVjMrdd9+NNWvW4Omnn8a+ffvwwQcf4F//+hdmz56t5rAAsJiWiIgoHKgaqIwaNQqLFy/Ghx9+iEGDBuGpp57Cyy+/jJkzZ6o5LABsoU9ERBQOVJ36AYALL7wQF154odrD8OGe+mHDNyIiIrWo3kI/XDGjQkREpD4GKgFINSoOBipERESqYaASgNTwjRkVIiIi9TBQCUBq+MZVP0REROphoBIAMypERETqY6ASAPuoEBERqY+BSgDsTEtERKQ+BioBcHkyERGR+hioBMCGb0REROpjoBKAu0ZF5YEQERF1YQxUAmBGhYiISH0MVAJgjQoREZH6GKgEwOXJRERE6mOgEoDU8I2BChERkXoYqATAjAoREZH6GKgEoGWNChERkeoYqATAjAoREZH6GKgEwBb6RERE6mOgEgAzKkREROpjoBKAu0aFDd+IiIjUwkAlAGZUiIiI1MdAJQC5RkUwUCEiIlILA5UA9K6GbzY7AxUiIiK1MFAJwBWncOqHiIhIRQxUAtCzhT4REZHqGKgEwN2TiYiI1MdAJQCu+iEiIlIfA5UA2JmWiIhIfQxUAuDUDxERkfoYqATgnvphZ1oiIiK1MFAJgFM/RERE6mOgEgCXJxMREamPgUoAUsM31qgQERGph4FKAMyoEBERqY+BSgDclJCIiEh9DFQCkFb9CAE4mFUhIiJSBQOVALSuQAVgnQoREZFaGKgEoFcEKqxTISIiUoeqgcrjjz8OjUbj8dWvXz81hyTTKQMV1qkQERGpQq/2AAYOHIgffvhB/lmvV31IALwyKnYGKkRERGpQPSrQ6/XIyMhQexg+dB41KmyjT0REpAbVa1T27t2LrKws9OjRAzNnzsSRI0cCnmuxWGA2mz2+ThWNRgMpVmGNChERkTpUDVTGjBmDd955B9999x3mzZuHgwcP4owzzkBNTY3f8+fOnYv4+Hj5Kzc395SOT276xhoVIiIiVWiECJ9P4aqqKnTr1g0vvvgibrjhBp/HLRYLLBaL/LPZbEZubi6qq6sRFxfX5uPp/8h3aGiy45f7z0JuUlSbX5+IiKgrMpvNiI+PD+nzW/UaFaWEhAT06dMH+/bt8/u40WiE0Whst/FwB2UiIiJ1qV6jolRbW4v9+/cjMzNT7aEAcAcqbPhGRESkDlUDlXvvvRfLly/HoUOH8Ouvv+J3v/sddDodZsyYoeawZHpmVIiIiFSl6tTP0aNHMWPGDJSXlyM1NRUTJkzAmjVrkJqaquawZJz6ISIiUpeqgcrChQvVfPlmMVAhIiJSV1jVqIQbd40KG74RERGpgYFKEKxRISIiUhcDlSA49UNERKQuBipBMFAhIiJSFwOVIHSuFvrso0JERKQOBipBsEaFiIhIXQxUguDUDxERkboYqATBFvpERETqYqASBDMqRERE6mKgEoSeDd+IiIhUxUAlCCmj4hDMqBAREamBgUoQco2KnYEKERGRGhioBMHlyUREROpioBIEV/0QERGpi4FKEHpXZ1rWqBAREamDgUoQrFEhIiJSFwOVINhHhYiISF0MVIJgjQoREZG6GKgEoWcfFSIiIlUxUAmCNSpERETqYqAShLtGhS30iYiI1MBAJQjWqBAREamLgUoQ7ExLRESkLgYqQehcDd8YqBAREamDgUoQOte7w6kfIiIidTBQCYIZFSIiInUxUAlCz2JaIiIiVTFQCUJa9eNgoEJERKQKBipBcHkyERGRuhioBKFnwzciIiJVMVAJghkVIiIidTFQCYKbEhIREamLgUoQWm5KSEREpCoGKkGwhT4REZG6GKgEITV8k2pUGpvseOizbfhpd7GawyIiIuoy9GoPIJx516isPlCOD9cdwdajVTi7X7qaQyMiIuoSmFEJwrtGpabRBgAoqbGoNiYiIqKuhIFKEN41Kg1WZ6BSUWdlt1oiIqJ2EDaByjPPPAONRoO77rpL7aHI3H1UnA3f6q12AM7ApbLeqtq4iIiIuoqwCFTWr1+P+fPnY8iQIWoPxYOcUXElT6RABQDK6xioEBERnWqqByq1tbWYOXMm3nzzTSQmJqo9HA9arxb6DYpApYx1KkRERKec6oHK7NmzccEFF2DKlCnNnmuxWGA2mz2+TiW9VzGtMqNSWstAhYiI6FRTdXnywoULsWnTJqxfvz6k8+fOnYsnnnjiFI/KTeddTNtkkx8rq+XUDxER0ammWkalsLAQd955J95//32YTKaQnvPQQw+hurpa/iosLDylY9S7Gr7ZhW9GpYwZFSIiolNOtYzKxo0bUVJSguHDh8vH7HY7VqxYgddeew0WiwU6nc7jOUajEUajsd3GqHOFcVJGpZ41KkRERO1KtUBl8uTJ2LZtm8ex6667Dv369cMDDzzgE6SoQW6hb5f6qDCjQkRE1J5UC1RiY2MxaNAgj2PR0dFITk72Oa4W74Zv9VZ3jQqXJxMREZ16qq/6CWfuhm+c+iEiIlJDWG1K+PPPP6s9BA/emxI2NimnfqwQQkCj0QS9xuLNR9EtORrD88KrRwwREVFHwIxKEO5NCT1b6AOA1e6AudHm93mSQ2V1uHvRb5izaMspGyMREVFnxkAlCN9NCe0ejzdXUCvVsbCehYiIqHUYqAShrFERQqDeNfUTZXCuSGquTsXiOl85ZUREREShY6AShNTwzSEErHaHnFnJS4oC0HympNHmDFCa7AJNrukjIiIiCh0DlSBccQpsDuEx7ZOT6AxUmpv6aWxyKL5nVoWIiKilGKgEIWVUhABqLc7CWYNOi4x4Z3fc5qZ+lMFJAwMVIiKiFmOgEoRUowK4A5VIgw7J0c5ApbSZjQk9MipWTv0QERG1FAOVIPSKQKXGtRQ5MkKHlFhXRqXZqR9mVIiIiE4GA5UgdB6BShMA54qf1BgDgBACFRsDFSIiopPRqkDl3XffxZIlS+Sf77//fiQkJGDcuHE4fPhwmw1ObTp/GRWDDikxoWZU3NM93j1YiIiIqHmtClSefvppREZGAgBWr16N119/Hc899xxSUlJw9913t+kA1aTT+AYqUYpApbyZGhWLIovCVT9EREQt16q9fgoLC9GrVy8AwOeff47LLrsMN998M8aPH49Jkya15fhUpdVqoNUADqHMqOjlGpV6qx31VhuiDP7fRtaoEBERnZxWZVRiYmJQXl4OAPjf//6HqVOnAgBMJhMaGhrabnRhQJr+kWtUInSINuhg1DvfurKawFkVTv0QERGdnFYFKlOnTsWNN96IG2+8EXv27MH5558PANixYwe6d+/eluNTnRSoSMuToww6aDQaefqnNEidirKYVvl9ODpcXofvthdBuHaKJiIiCgetClRef/11jB07FqWlpfj000+RnJwMANi4cSNmzJjRpgNUm9T0rVZRTAsgpCXKHlM/YZ5Rue/jrbjlvxux7Vi12kMhIiKStapGJSEhAa+99prP8SeeeOKkBxRupIyKWVFMCyCkJcoWW8dpoX+82jllV2wOvpKJiIioPbUqo/Ldd99h5cqV8s+vv/46TjvtNPzxj39EZWVlmw0uHHjXqES6CmdDWfnTkYpp61xTW/VWm8ojISIicmtVoHLffffBbDYDALZt24Z77rkH559/Pg4ePIg5c+a06QDV5g5UPDMqofRS8SymDe8W+nUWZyAV7lNURETUtbRq6ufgwYMYMGAAAODTTz/FhRdeiKeffhqbNm2SC2s7C72fYloASA5h6qejZFSsNgesdmcgVc9AhYiIwkirMioGgwH19fUAgB9++AHnnHMOACApKUnOtHQWPlM/EV4ZlSDLkztKjYo07QOEd0BFRERdT6syKhMmTMCcOXMwfvx4rFu3DosWLQIA7NmzBzk5OW06QLX5Tv141qiU1XX8VT+1ykAljMdJRERdT6syKq+99hr0ej0++eQTzJs3D9nZ2QCAb7/9Fuedd16bDlBtUqBiczj7i0QanG+ZNPVTUdfxi2nrFAW0nPohIqJw0qqMSl5eHr7++muf4y+99NJJDyjc6BUbEwJAZITzLUuMcgYqVfVNsNkd0Ot8Yz6PYtpwDlQ8pn646oeIiMJHqwIVALDb7fj888+xa9cuAMDAgQNx0UUXQafTtdngwoFO6xmASMW0iVER8rHK+iakuhrASYQQnp1pwzhQqbW4x8aMChERhZNWBSr79u3D+eefj2PHjqFv374AgLlz5yI3NxdLlixBz54923SQavJOlEiBil6nRUJUBKrqm1BZb/UJVKx2B5Td6MO59kOZUWGgQkRE4aRVNSp33HEHevbsicLCQmzatAmbNm3CkSNHkJ+fjzvuuKOtx6gq74yK1EIfAJKindM//pq+Kad9gPCe+mExLRERhatWZVSWL1+ONWvWICkpST6WnJyMZ555BuPHj2+zwYUD7xoVadUPACRHG3CgtM5vQa3FKzAJ56kfz4wKa1SIiCh8tCqjYjQaUVNT43O8trYWBoPhpAcVTnQ+gYpvRqXCzxJln4xKGGcqPItpw6eDblV94BVVRETUNbQqULnwwgtx8803Y+3atRBCQAiBNWvW4JZbbsFFF13U1mNUlU7jDlQ0GsCod79l8tSPn4yKspAWcE79CGXRShhRFtM2hElG5eutx3Hak9/jP6sPqT0UIiJSUasClVdeeQU9e/bE2LFjYTKZYDKZMG7cOPTq1Qsvv/xyGw9RXXqdO1CJitBBowhc3BkVfzUqzg//WKNzqsghILepDzfhWEy7/Zizw/GWwmqVR0JERGpqVY1KQkICvvjiC+zbt09enty/f3/06tWrTQcXDpRTP5EGz7crKdq50sd/oOIMSuKjIlDjCgQarQ4Y9eG3fDsci2mlQK+6gdM/RERdWciBSnO7Ii9btkz+/sUXX2z9iMKMsphWWZ8COItpgeAZlRijHnqtBjaHQEOTHfGI8DlXbcpApd41RaXMHKnBHag0qToOIiJSV8iByubNm0M6T+0PuLamCxKohDL1Y4rQITJChxqLLWyXKCunfuwOAatd/cyP9P5V1TNQISLqykIOVJQZk67Ec+rHf6Div5jWOfVjitDCZHAFKmEyreJNGagAzukftQMVKairYkaFiKhLa1UxbVeibPgWGeE/UKmss/qs6PHOqADh2/St1jtQCYNxSjU+1Q1NYbtaioiITj0GKs0IVqMiBSo2h4C50fPDXmr4ZtK7A5VwbfpWZ/Ec18ms/CmqbsTCdUdO+l6lYMlqc/j0pCEioq6DgUozgq36MUXoEO0KXrzrVCxeUz9A+Kyo8eZv6qe1nlu6Gw9+tg1fbz1xUmNSdvat4sofIqIuS9VAZd68eRgyZAji4uIQFxeHsWPH4ttvv1VzSD6UDd+iInzrNpJi/Hen9Zz6cb7N4TCl4k0IgTpXk7cYV8+Xk8mo7C+pBQCU1vh2620J5XvFlT9ERF2XqoFKTk4OnnnmGWzcuBEbNmzA2WefjYsvvhg7duxQc1gedLrAxbSAu5eK98aE0nRFuNeoNDTZ4XCVgEg7QJ/Mfj9HKxtO+hqA5xYEXPlDRNR1qRqoTJ8+Heeffz569+6NPn364G9/+xtiYmKwZs0aNYflIViNChC4l4qUUTFGaOUAJxxrVKRCWo3GXXPT2qmfOotNXgF1sh1ulUEdAxUioq6rVZ1pTwW73Y6PP/4YdXV1GDt2rN9zLBYLLBb3lILZbD7l4wrWRwUAEqP8L1GW9vox6XUwRYRvjYpUSBtt0Mv319rMz7GqBvn7k8+ouMdg5tQPEVGXpXox7bZt2xATEwOj0YhbbrkFixcvxoABA/yeO3fuXMTHx8tfubm5p3x8yhoV72JaAEiOcS9RVuooUz9SIW20UScHKq3NhhytrJe/P9mMSiOLaYmICGEQqPTt2xdbtmzB2rVrceutt2LWrFnYuXOn33MfeughVFdXy1+FhYWnfHzKGhV/GZVA3WndxbTasA5UauVARY8oVyDW2syPVJ8C+C55bgmb3YEmu7t3Cqd+iIi6LtWnfgwGg7yZ4YgRI7B+/Xr84x//wPz5833ONRqNMBqN7Tq+5mpUAnWnlTIqRr3OXaMSllM/7hU/0hRV6zMq7kCloan1Uz9SV18JV/0QEXVdqmdUvDkcDo86FLUF60wLBC6mtdjcGRXTKcyofLShEPOX72/18+WMiqJGpb6VQYZy6udkMireRcdso09E1HWpmlF56KGHMG3aNOTl5aGmpgYffPABfv75ZyxdulTNYXnw6KPip0al+akfZY1K6B1WhRB4ePE2WGwO/PWSQX5f2+4Q+L/F22G1O3DuwAx0T4kO+foSz6mfkyv69cionET2yDtQqebUDxFRl6VqoFJSUoJrrrkGJ06cQHx8PIYMGYKlS5di6tSpag7Lg76ZPirJrj4qvoGKuzNtZCsCgOPVjfhwnbMGp7CiHm9fOwqxpgiPc6rqrbDana+z64S5VYGKe+rHPUXVFlM/dSex6sc3o8JiWiKirkrVQOWtt95S8+VD0uzy5Ghn8NDQZEeD1e7TM6W1e/1IHV4BYP2hSsz891q8d/1oJLiWQwOedTG7i2owbXBmyNeX1ErLk416ufNua6ao6iw2j2Dt5DIqrFEhIiKnsKtRCTfKYlp/NSoxRj0MOufbWK5ooy/1UTFG6FpVo7K/1BmoDMiMQ1K0AVuPVuPaBes9dhIuU7Sp313Uup4yymLak1n1o+yhApzc8mTpfZJm3bjqh4io62Kg0gytJnhGRaPR+K1TOdmpHylQmdQ3FYtuPh1aDbClsAoliuCkzCuj0hp1ihoV99RPy6dtCiuchbSZ8SYArtb8DhHsKQFJmaeUGOe0Wk2jDfZWXouIiDo2BirNaK5GBfC/RNlfMW3Lpn7qAAA9U2PQOz1W/tAuMSsCFUXQcri83mcX5FAoi2kjT6KDrlSf0js9Vj7W2lVO0utnxJnkY+xOS0TUNTFQaYZnjYr/kh6pO22FYmNCy0l2ppUyKj3TYgAAaXGuQKWmUT6n3GvH5oLilmdVlMW0LelMW1BUg9eX7ZOXYUtLk3ulxshTNq0tqJX6qMQY9fKOzlyiTETUNTFQaYZUo2LQaz2CFiUpo1JZ7wxU7A4hr8Yx6bWINDjf5lADFXNjkzzF0yPVuZInLdaZXVBO/Xjv2FzQiukfqd9JjDGiRat+nvtuN55fWoAFqw4BcGdU8pIiTyozA7gb40UadIiPdBYrV9Vz5Q8RUVfEQKUZUo2Kv/oUiffGhFKWAXBmVFq6KeGBUue0T1qsEXGuJcnpcX6mfmqd30sf5rtPtLygttZjrx9n9iKUKSqpePbTjUchhJADlZzEKPk6rW361qholifdG1f+EBF1TQxUmiHVqET5WfEjkbvTujIcyuW1yqkfi80RUoHpAde0j5RNAYBUOaPinvopc73euJ7JAIBdrcmoWJWrfkLPqJS6Mjt7S2qx47hZnvrJSYpU7MLcuqkfKaAzReiQEMVAhYioK2Og0gyphX6gQloASIrxzKhIGYkInQY6rcbjuY225oMAuT4lNUY+lhYr1aj4ZlTG90oB4MyoKJcvh8Lfqp/mVuw02R2oUEzFvLf6ECpdS4izE9yBSqszKor6HilQ4RJlIqKuiYFKM6QalUCFtIByvx9n4KBs9qb8LxDa9I9yxY/EX6Ai1aic3iMJeq0G5kYbTlQ3oiVqFX1UlH1iggVUFXVWKOOhzzYdAwAkREUg1hTRosyMPw2K949TP0REXRsDlWbkJUUBAHqlxQQ8J9m1dNidUXHtnOz64NdqNTDqQy+o9V7xAwBprqW6pWZnIFJvtcnXyoiPlIOalhTU2uwOeazRXoFKsCBDmvZJjjYgJcYAmyv7kpsYJV9LGmNrSIFepEGL+EhnEMiMChFR18RApRmDsuPxy/1n4dnLhgQ8R852mC0QQnjsnCzxbq0fiM3uwKFyKaPirlFRZlQcDoGyGmdQZNRrEW3QoV+ms3/JrhZ0qK1TBCPRRh20Wo085mCZn1LXlFN6nAkXn5YtH89JjATg7uDb2oyK/P7pFVM/3O+HiKhLYqASgtykKBj0gd8qaelwQ5MdNRabR42FxL1kN/gOyoWVDWiyC5gitMiKj5SPSw3fbA6BynorylzTTCkxRmg0GvTLiAMA7D4RekZFqk+J0GlgdE1PSVNcoWRUUmONuHS4b6ByshmVBj/Lk9nwjYioa2Kg0gYiDTrEmZwfziXmRo/ltfI5ITZ9kzYj7JESA62ib4tBr5X7tZTUWOSutCmuQl4po9KSPX+UXWlbMk5loDIgMw79MpyvLU2TnewuzMqps4RIFtMSEXVlDFTaSLqrhqTYbIHFq5gWQMgbE+73szRZopz+kephpEyLFCzsL63z6OMSjByoKAqFo0LY70dabSRlc565bAhmjM7DJcOyXdcLHqg02R3YdrQ64P490nsUGaFDvDz1w0CFiKgrYqDSRjJcm/EVVTcqMgK+NSrStMae4hq594iSv6XJklS5FqYR5a5gQWrfnxFnQmJUBOwOgR3HQ8uqKHdODjROf5QZFQA4LTcBcy8djFhXc7pIQ/Cpn/nL92P6ayvx0YZCv4+790nSIsFVTMtVP0REXRMDlTYi1akU1zT6LE8GoGj6ZkeJuREXvbYSf3xzrU/fE6krbU8/q4ykrE1JjUVu9iZlVDQaDUbnJwEA1h6oCGnMdYqutN7jDLVGxR85oxKgj8ouVx3NwbI6v483+smoVNc3tbhHDBERdXwMVNqIssW9cudkibKN/obDlWhscuBIRb1HXxRAmVEJPPVTWmORp1+kpdEAMCbf2aF2zYHykMZc6woklDUqUaFkVFyvnRrjP1Bpro+KFOjUNPrPuHg0fHPVqFjtjlbvxkxERB0XA5U24q5RaZR3//U79dNkx2+FVfJxZd+TslqL3OE1PyVYjUqj3OxNKqYFgNN7OAOVDYcqYLO7VxfNWbQF57y0XK5Jkfib+olqZtoGUGZUDH4fl/f6CXANaRuAmkb/0zkNikAvyqBDhGsbA07/EBF1PQxU2oiUUSk2N/rNqERGuBu+bVEEKnuK3YGKVFuSnxLttxOu1PStxGzxKGiV9MuIRXxkBOqsdmx3XetgWR0+23wMe4prsflIpcf1/K76kQMq/8uoG5vsciYkNcbk95zmsjJSFsk7cFK+BuCsUdFoNIodlBmoEBF1NQxU2kiaYtWPPHXhp0alzmLDtmPV8vHdRcpAxXl8YFac/9fws+onWZFR0WrddSrS9M/nm4/Jj0tLnyX+MypSkOE/iJACJINOi7hI/9sKRBmljIpvoFJnsclTQrUBpn4avAK9UAKVgqIanP70j/hg7ZGA5xARUcfDQKWNuAtdGz0yAhKTKwDYdszsUbvhkVE55syCDMyK9/saUsFukbkRlfWexbQSafpn7YFyCCHwxRZFoFLqWbzqt5g2xPqS1Fjn0mR/ggU7ypqcQBkViyvQk4K7hKjmV/4sKyhBkbkRS3cUBTyHiIg6HgYqbUQqLG2yC5yobgDgvzPthkPOFTmZruXMe4pr5J2KpYzKoOwAGRXX9JLV5oAQgEYDJEZ51omMcWVU1h+qxMbDlThU7l4CfaDMM6MiFdPGGCN8xlkfoHC11KvRnD/BimlLFYGKv2Jau0PAavfs7Jsgb0wYuI3+iaoG1zU5PURE1JkwUGkjBr1W3kX5sCs48NeZVvrwvnBIJgx6LRqbHCisrIe5sUkOKgJlVEwROsSa3NMtSVEG6LSeWY3+mXGIM+lRa7Hhb9/sAgD0cBXmSrsyS9xTP+6Aqrn6EmlZdKClyc5rBG7DLxXSAv6DCuVeSJEtmPo5VuW8bqAsDRERdUwMVNqQVKdypEIKVHynVCTD8xLRO8294/EuV/FrVrxJbpXv9zUUAYL3tA8A6LQajHYtU958pAoAcOeU3gCcU0bKD3JpVY5nMW3wVT/N9VABlJ1pbT69T0rMnlM/3o8rAxVpx+lQutMelzMqDFSIiDoTBiptSFr5I2US/LXQlwzNTUDfdGfb+z3FNfIqnQEBsikSqU4F8CykVTq9R5L8fUqMARcMzpSnag4q6lT8rfqJaqbhW2mtM3MRqIcK4A7KHAKw2DxXD0k9WKTHvXujSD8b9Vp5ryOpO22wjMrxagYqRESdEQOVNpQR57lc1+hn6gdwZkIy403o49qfp6C4ttn6FIlUpyJdxx+poBYApg/Ngl6nRQ9XS36poRzgXnXjb9VPY3M1KiFM/QC+AY8yo6Icg8TfztMprn4tpV7N8SR1FpscxNRabAH3ECIioo6HgUobSvMKVPwV0wLAabnx0Gg07oxKUU2zK34k6XHNZ1T6Z8bJ9TKXDssB4O50e8AVqNRabDjgamHfLTnKPc5mVv3INSpBMio6rUaetqnzqhlRZlQAwOwTqLjb50vSY90rqvyRipclrFMhIuo8/DfCoFZJj/P88A5UozI0JwEA5IzK/tJaSDmAZjMqzdSoAM5A4Z3rRqO0thGDc5yBT085o+IMTtYfrIDdIZCXFIWcREWgEhG8mDaUGhXAOZ1ksVl9pnZKzJ7BhndQ4W9pt7Lrrz9SIa2kprFJLsAlIqKOjYFKG0qP9cqo6BV9VBRBy9DcBADOwtkYo17+sE6KNvhMH3lL9QhUAhfdOgMUd3amhyujIk39rNpXBgAY3yvZ43nBVuwIIUIOVJQN7pSk5+u0Gtgdwmfqx7vZG+AOAMtqrbA7hM9KJ2lpsoR1KkREnQenftpQepCpH2WGYIgry6HRaNAn3b1L8sCsuIBN1CQexbTRwYMFJSmjcrCsDnaHwK/7nZ1rx/ZM8TgvUrFix1ud1S4HEoGyORKpiZwyM9Nkd6DC1aguL8mZxam1eBbI+qtRSY4xQqtx9lgpr/OtUznOQIWIqNNioNKGgk39dE+ORmqsEWf0TpE7rQJAX9f0D9B8fQrgVUzbTFZDKScxCgadFhabAzuOV2PnCWdNzNge3hkV9+aJ3qRsSJRB57FSyJ9Ig28b/fJaK4QA9FoNcl2BineNSoOfGhWdViMHRt7FuID/qR8iIuocOPXThqR/+UuLTpRZlGijHisfOAsGnWds2CfdHag0V58CeNaoJAfpt+JNp9Wge0oU9hTX4v01zv1w+qbH+kzhSIFKk12gye5AhGK80j4/zU37AJ69VCTurrZGxLka1/mu+vGtUQGc2aqSGguKzY0YlO0Z0DGjQkTUeTGj0oZ0Wo3Hh7h37xSjXucztdM3vWUZlRijHpP7pWFEt0RkJUS2aHzS9M8Xvzn3/xnbM9nnHGXRr3dWRa5PaWbaB/DfRl9atZMaa5Q77AYupvV875QbMnqTeqhIjfKYUSEi6jyYUWlj6XEmFLumJ4z65uPAgVnxiDPpkRBlQLekqGbP12g0eOvaUa0am1RQK9WBjPMTqBh0WrnQtcFqR5zJvXpGmRFpjr+iXCnISIs1yr1bAgUqkd6BSoCVPw6HwAnX1E/f9FisPlDuM51EREQdFwOVNuYsdnU2b/POCvgTHxWBb+48AwZFJ9ZTRcqoAIBWA4zp4RuoaDQaREboUGux+az8CXXFD6DIqFh8p36cGRVnAOQ9TdNgdQZRRq/3Tqr/KfaqUSmvs8Jqd0CrAXqnx2D1gXJO/RARdSIMVNqYsqA2lIwKAI8+JqdSD0WgMjg7PmCvkUiDFKh4fuC3pEZFXj3U5Dv1o8yoeE/TNNr8Z1SkFVWlXk3fpPqUtFiTXKTMqR8ios6DgUobk/qgGPXaZpcatzdp6gfwXZas5G8H5bUHyrH6gHNJc2jFtK6pH0VGRVqxkxprlDMmoTR8A9w1Kt4ZFSlQyUowyQW6zKgQEXUeDFTamPQv/1CmfdpbnCkCmfEmnKhuxIRegQMVKZtx+webMTQ3HtUNTVhzoAKAMwAblpfQ7Gv5a8VfKmdkTPKuyYFW/QTKqHjXqByTA5VIuUCXGRUios5D1VU/c+fOxahRoxAbG4u0tDRccsklKCgoUHNIJ03qc+KdEQgXf79iKP7vgv4+HWmVpg3KhEYDFJkbsXRHMdYcqECEToOZY/Lw072T0C+j+WXU0f5W/biyIWlx7hoV34yKb8M36TmAc/pJuengcVchbXZCZMC6FyIi6rhUzagsX74cs2fPxqhRo2Cz2fDwww/jnHPOwc6dOxEdHd38BcLQwKx4RBl0GJzd/FJjNYzvlYLxQbIpAHDnlN64fkJ37DhuxvZj1aiz2HH5yBxkt2A5tHvVjzNoEEK4MyoxRpRrnB1qfYtpXVM/Bs9AJTna3aOmvNYirwKSpn4y402KjIr6gYoQAo9+sQMJURG455y+ag+HiKjDUjVQ+e677zx+fuedd5CWloaNGzfizDPPVGlUJyc11oi1D0+WP6g7qlhTBE7vkYzT/awMCkWUq4W+1JnW3GCD1ebMlqTGGmFxfR+omNbkVYgs9agpNltQbFYEKtXKqR//WRp/LDY75n6zG2f3S8OZfVJbdY/BlNRY8J81hwEAt0zs2WwnXyIi8i+s5ieqq53LepOSkvw+brFYYDabPb7CUawpwmfjvK7GuyBXWvETZ9LDFKHzaPgm1asoz480+Nb4+KtTkaZ+lDUq5hBqVJbtLsE7vx7Cc0t3t+zGQlTp2tMIAAor60/JaxARdQVhE6g4HA7cddddGD9+PAYNGuT3nLlz5yI+Pl7+ys3NbedRUqii5L1+nNkNqYeKlAmRggqH8OyA2+jKtJj0voGKd3faxia7vGQ6WxGo1FpscCjqWPzZX1oHAHKzuLZWVe8Olo6UM1AhImqtsAlUZs+eje3bt2PhwoUBz3nooYdQXV0tfxUWFrbjCKklfDMq7q60gHNVj5R0Uq78aQySUfHuTltU3ShfKyEqQu6iK4Q7QArkgCtQKa+zwmLz3YDxZCkDlcLKhiBnEhFRMGERqNx+++34+uuvsWzZMuTk5AQ8z2g0Ii4uzuOLwpN3C33vrrYajUZu+qZseS/XqPhZNZUe6wxUpGkkuZA2wQSNRgOjXosInTP6aa6g9lB5nfx9qZ/9g/z5cVcxdp0IbbqxukEx9VPBjAoRUWupGqgIIXD77bdj8eLF+Omnn5Cfn6/mcKgNRXntnqzsSivxV/wqZWCMfqZ+vNvoH3UFKtJqJI1GE/IS5YNl7kDFuzeLP8v3lOKGdzdg9vubmj0X8Jr6YaBCRNRqqi5FmD17Nj744AN88cUXiI2NRVFREQAgPj4ekZEt2xmYwovUmbbJLmC1ObD9mDMTodwuQN6YUJlRaQo29SPVqDgDi1/2lgEA+mW4d6CONelRUWcN2vStqt6Kijp3xsO72603IQT+8cMeAMDB8jo02R2I0AWP8asaFFM/DFSIiFpN1YzKvHnzUF1djUmTJiEzM1P+WrRokZrDojagDDSKqhux7pCzs+1ZfdPk4+7iV/eHeqCGb4C04aMzsKi32vDDzmIAwIVDsnyuGSyjosymSOML5tf95dh0pAqAs/4llAyMd0ZFubKJiIhCp2pGhX95d14GV71Ik13g623HYXcI9E2PRV6yIqNi8qxRsTsErHZnoOLdQh9wL08uq7XgfzuK0dBkR15SFIbkuJvrxRojXNcMnFFR1qcAQHFN8MDjHz/u9fj5RHVjsxtJmhUZFYvNgdIad+8XIiIKXVgU01LnJAUbX245DgCYOiDd43HvqR/l6ht/xbTJ0QbotBoIAby96iAAYPrQTI/NH0PKqLhW/EhPKw6SUVlzoBzrDlbAoNPKmzpKRbzBVCmKaQH2UiEiai22y6RTJtqoh7nRht1FNQB8AxVl3xPAc7dmf31UtFoNUmOMKDI3YutRZ3PAi4Zme12z+WLaA66pnwGZcdhx3Iwir6mcDYcqcKyqATqtBgtWHQIAXDkqB3UWOw6U1uFEM1NFgHvqR2r7f6SiHiO6+W9kSEREgTFQoVNGWaeSFmv02f/Ie9WP1OzNoNdCG6Czb3qcUQ4s+qTHoK+ikNZ5zeZ3UJZqVMb2SMaO42Z5s0QA2F1kxuVvrPY4X6/V4JaJPfHB2iMAQsyouAKVXmkx2FNciyPl7KVCRNQanPqhUyZasd/RlAHpPsGHNPUjZT/k9vl+6lMkyjqP6YoiWklzUz9CCBxyBSrSPkZF5ka5Xuq3wioAQFK0AaPzkzCqeyIemz4AOYlRyHQtgz4eQjfbaleNyuDsBACc+iEiai1mVOiUUWZUvKd9AGWg4vxQl5Ym+6tPkSj7sEwfGixQ8Z9RKa2xoM5qh1YDjOrunIqpt9pRa7Eh1hSBfSW1AICLhmbh8YsGejw3K94ZJJ2oDp4dabI75CzR4Ow4fLqp5b1UHA4BuxDNLoMmIurs+LcgnTLRrkAl2qDDuJ6+uzDHeNWoyD1UgmRUpJU/Q3Li0T0l2ufx5mpUpPqU3KQoxEdFyIGNtOR4rytQ6Z0e4/PczHhnRqW5GhXlip+BrumulvZSueqttZj43DL5PSEi6qoYqNApI7XRP7NPqt9Os3Emz1U/wXqoSC4dno0JvVLw0LT+fh9vbupHqk/JdwU57h2ZnXUqUkalV6pvoJKV4Dy3os4aNICQmr3FmvTy6xSZG0PeU8jhEFhzoBzHqxt9er4QEXU1DFTolBnXKxkGvRZXj+3m9/EYo2cxrbSLsjFIoJKTGIX/3jgGY/1kaAB3RiVQH5VDXoFKhitQKapuRIPVjmOuQtleab6BSnxkhJztCZZVkQppE6IikBxtQGSEDkIAx0LcnLDOaoO0+XN5rTX4yUREnRwDFTplZo7phl1PnodxPVP8Ph7jlf1wT/20/o9lcxmVA16BitSWv8jciP2ltRACSIyKQHKM0ee5Go0Gma6syokgK3+kDQkTIg3QaDTIS3I2hwu1TkW5SWN5XWgbJhIRdVYMVOiU0gVYZgz4FtM2yMW0gTMqzYlrppjWe+pHyqiUmBvlaZ/eabF+nwu4N0A8FiRQUWZUACA3yfmcwhAzKsoal1B3diYi6qwYqJBq4hTFtEIIWEIopm2OsjeL9xYNdofA4XKvQMW1kqdIEaj09DPtI8mUV/40P/UTHykFKs6MindBrRACD3yyFbf+d6PHWKsVgUp5Had+iKhr4/JkUo009eMQzmxKW2RUYhXXrLfaEW10/xE/VtmAJruAQa9FlmsFj3KjQw2c2R9/9SkS98qfYFM/noGKPPVT7hmoHK1swKINhfLrS0GTMqNSXsuMChF1bcyokGoiI3SQZoZqG20hrfoJ5ZrSdJOyTqWxyY55y/cDALonR8nN56TgoNjciH2lrhU/QQIVaeVPsKZvUqAiT/24NjD0bvq2en+5/L1ybyCPGhUW0xJRF8eMCqlGo9EgxrUfkLnRJmcPTmbqR6PRINakR1V9E2oam5ARb8KWwirM+WgLDrg2I5wxOk8+X65RqbFA46oHOdmMSlW9u5gWgLxj9JHyeggh5E0U1xxQBCr17iyKMqNSxqkfIurimFEhVUk1JUXVjfhs8zEAwOj8k9u8T5r+MTfa8FthFS6b9ysOlNYhLdaIBdeNwnXj8+VzU2IM0Gqc9Ss2h0C0QSd3oPUnS171E6RGRZr6iXJP/Rh0WtRYbCgodm7QKITA6kCBiqIQuIzFtETUxTFQIVVJQcX8FftR02hDz9RonOOn3X6LrmmUutM24Z1fD8HuEDijdwr+d/eZOKtvmse5ep0WKYqlyD3TYuSMhz9SRqXGYgvYq0Ve9eOqUTFF6HBmn1QAwNe/nQAAHC6v9yjIrVZM/XgW01p8ioKb8/3OYjz6xXY02R0teh4RUThioEKqkpYo/7K3DABwy8SeAXdODpUU/ByvasQ325yBwT3n9EVClMHv+emKjQ79daRVijbq5dVKgbIq7hoV9+tNH5oJAPh663EIITymfQDvqR9lbY0D9daWtdF/fuluvLf6MNYdrGjR84iIwhEDFVKVtPIHcG76d/Fp2Sd9TWk66YN1h2GxOdAnPQZDc+IDnq8MVIItTZbHKe2iHKBORa5RcU39AMDk/ukw6rU4VF6PHcfN8rSPFJNVBpj6AVpeUFvhqmsp44ohIuoEGKiQqqSgAgBuOrMHDPqT/yMpZTy2HzMDAK4cmRt0Oicj3j3107sFgYq/jIrDIdwZlUj3vcUY9Ti7n3Pa6autx+UVP2PynVsBKKd+lMW0AFDagoBDCCFnZ5RZGiKijoqBCqlKmvpJijbgD6Pymjk7NLGKLI1eq8Elw4JnadJjFVM/IQQq7qZvvhmVWsU+PXGKQAUApg/NAgB8sPYISmosMOi1cvDiWUzr2f6/Jb1U6qx22FwDYKBCRJ0BAxVS1aDsOADA7Wf1QqSh9cuSlZRZmrP7pXkUy/qT7go8DDqt3JwtGHnqx09GpdoVHJgitD79YM7qm4Yog07u7zI8L0Hea8jf8uTUWOdjLelOK007AUBlPZc2E1HHxz4qpKoZo/Jwdr80eTVNW1BmVK4cmdvs+VJw0js9Bnpd87F7sIyKe8WPb+FupEGHKf3T8eVvxwEAp/dIRqKr4FYZVEiBSn5KNEprLC3KqCgDnioGKkTUCTCjQqrSajVtGqQA7oxKSowRk/qmNnv+6O5JeOrigXj2siEhXV8a73E/GxNKHWaVhbRKFw7JlL8f2yNZPk+qa7E7BGoszoxLD9d+RGUtKKZVLm2uauDUDxF1fMyoUKczuX8ahq6Px7Xju4eUIdFqNbh6bPeQr5+T6J76cTiEx3Jq7w0JvU3sm4ruyVEQAE7LS0BxtcXjebWK+pR8OVBpXUalkjUqRNQJMFChTic9zoQvbp9wyq6fGW+CTquB1e5AcU2jR0bIe58fb0a9Dt/eeSY0Guf3UvfahiY7Gpvs8vOjDDp5H6KWLE9W7hnEqR8i6gw49UPUQnqdFtmuglrvHZHdS5P9N5cDnLUqUqFtrFEv91IxNzTJPVTiTBFyEXB5XWtrVJhRIaKOj4EKUStIBbhHKjwDFSmLER8go+JNq9XIHWwr65vkQtq4SD2SY5zHW5JRUdaomBubYHe0rP0+EVG4YaBC1Aq5rkCl0CdQCV6j4o/UGK6q3uqRUUmOdmZUKuqtsIW4b49yukcIz8CFiKgjYqBC1AoBMyrN1Kj4I2Vfqhqa5H1+4iIjkBRtgEbjDDhCLYz1nu5hnQoRdXQMVIhaIVCgUh2kj0ogUkalur5JzoDER0ZAp9UgyTUtFGqdiveSZK78IaKOjoEKUStIgUphpWcvleZW/fgj1ahUNSinfpwL8lpap1KtYkalrNaCf/9yAJUt6KRLRNQcBipErSAFKqU1FjRY7fJxaXlwi2pUXEGNZzGt85hUpxJqLxXp9ZOiXcFPO2ZUXl+2D39dsgvvrj7Ubq9JRJ0fAxWiVoiPipCzHoWV7ukfuYV+SzIqke6gQtqQME7qrhsrBSqhZSmk1++e7Ayk2nO/n42HKwEARyt9O/YSEbUWAxWiVspzBQNSL5XGJjssNufqnNZkVKobrB7LkwEgOVqa+mk+o6J8/e6urrbtteqnscmOXSfMAJxZJiKitsJAhaiVvAtqS8zOD2i9VoMYY+hNn6VApcqrmBYAUlpQoyJlT3RaDXJcDenaK6Oy64QZTXZnzxYGKkTUlthCn6iVcr0ClTUHywEAA7PjodFoAj7PmxSUVNY3we5wZkSkqZ/kFnSnde/cHIHEaHcTufawpbBK/r60BXsTERE1h4EKUSvleTV9W7WvDABwRq+UFl0n0bXqp7reCqmRbFykewdoILQaFbnZXFSEezqpnQKV3xSBSnmtBXaHgE4berBGRBSIqlM/K1aswPTp05GVlQWNRoPPP/9czeEQtYhy6sfhEHKgMqF3ywKVBGXDN0VnWsC9PDmUVT/VrhU/CZERirb87TP189vRavl7hwAquESZiNqIqoFKXV0dhg4ditdff13NYRC1ijJQ2VVkRlmtFVEGHYbnJbboOtKqn3qrHfWupc5SMW2Ka3lyKDUqUkYlMcogZ2lCWZ7c2GTHNkWg0VJV9VYcLKsD4Nz1GQBKahpbfT0iIiVVp36mTZuGadOmqTkEolbLSoiEVgNYbA4s3nQMADAmPwkGfcvi/1iTXm6V7z7mmVFpaLKj3mpDlCHw/7JSV9r4qAiP/YOCEULgxnc3YOW+Mrx/4xiMb+G0FeDOpuSnRMMUocOuE2YW1BJRm+lQq34sFgvMZrPHF5FaInRaZLlW13yy6SgAtOqDXqvVeCxnjjXq5fqOaKMekRHOLEVzH/5Vivb9UkalzmqH1RZ4Q8PvthdhpWvKSlkQ2xJSfcrQnHikuvq+MFAhorbSoQKVuXPnIj4+Xv7Kzc1Ve0jUxUnTP1KQcEbv1FZdRwosAHchrSQn0RkMHS733FfIm1yjEhWBWJMeUi1roKxKY5Mdf/tml/xzaxu1yYFKbgJSXcW/XPlDRG2lQwUqDz30EKqrq+WvwsJCtYdEXZwUqABAWqwRfdJjWnUdj4yKyXN6p2eq85r7S2uDXkPZFVeZpfHeqFDy718OeAQnRyuDB0L+CCHw29EqAK5ARYWMihACn206ime+3Y17PvoNN7yzHkt3FLXb6xPRqdWhlicbjUYYjUa1h0Eky1UEKhN6pbSof4qSsuW+d0alZ1o0sAPYVxJaoCIFKIlRBlTWN/ndJLCouhGvL9sPAJgxOhcfrivEsVZkVI5VNaCs1gq9VoMBmXHYfKQKQPsGKssKSjDno988jh2pqMe5AzPabQxEdOp0qECFKNwoMyqtqU+RJCiCE+/2+73SQsyoyDs3O6eR4hWbHQLAyr1l+PfKAzhSXo+jlQ2w2h0Y0S0Rt03qhQ/XFeJoVQMcDgFtC/qfSHUt/TPjYIrQIU2FjMqKPc4am2F5CRjdPQnzVxzAsaoGCCFaHTgSUfhQdeqntrYWW7ZswZYtWwAABw8exJYtW3DkyBE1h0UUMmWg0tL+KUoJyhoVk1dGRZ76qQt6jep6dx8VQNFIzlW78uTXO/BzQSkOlNXBancgPc6Ipy4ehMx4E3RaDaw2R4tqSxqb7PhwnfP/1aG58QDgd+pnX0kNbnx3A7a6poja2q/7nYHKzWf0wN1T+wBwLvVur32OiOjUUjWjsmHDBpx11lnyz3PmzAEAzJo1C++8845KoyIKXf/MOEzolYLcpEikx5lafR1lFkXqoSLp4QpUSmssqG5oCrjhoTujEuHx38r6JpTXWrCn2JmRWXDdKPROi0FGnAl6nfPfKhlxJhyrasDRyvqQ7qPOYsNN723Ar/vLYYrQ4vcj8wD4D1T+u+YIfthVjJQYA4bkJDR77ZYorXHf1+k9kmGK0CE52oDyOiuOVzV6BIBE1DGpGqhMmjQJQtk8gqiDMei1+O+NY076OonKGhWvjEqMUY+MOBOKzI3YX1rrt6GcxeZuFic1kJP+W1lvxfpDlQCAPukxOKtvms/zc5MiXYFKA0Z0Cz5Wc2MTrluwHhsPVyLaoMPb147C4BzPjEqNxYYGqx2RBh0KimoAAMer274J3OoDzv2VBmTGyfsbZSaYXIFKAwZkxbXJ61TXN0Gna9lmk0TUNjrUqh+iziohyPJkQFGnEqCgVprm0Gjcq4YSFfv9rDtYAQAYnZ/k9/k5ic4pLOUqoAOltXj5hz1ocAVAkhf/twcbD1cizqTH+zedjjE9kuXHYo16GF0N78pqLRBCoKDYGagUVbdu+XMwv7p6wIzr6R5DVrxzOfeJNnq9BqsdZ73wMy545Rf+w4pIBQxUiMJAfFTgYloA6JkaDcCzTuVfK/bj1v9uRIPVLm8+GB8ZIRfDJkS7MyrrDjkzD6Pzk+GP1KtF2mARAJ7+Zjde/mEv3lp5wOPcH3cXAwCeu3woTstN8HhMo9HIWZWSGgtKay3yvj8nqto+o/Lrfud9jeulCFRcTfiOtdHrHSirRUWdFYfL69nIjkgFDFSIwoBy1U+cyXd6oacroyItUa612PD3pXvw7fYiLNl2wl2foriO9H1hRQN2Hnd2cR7dPbSMihACm484p4uWFZTK5x0ur0NhRQMidBqcEaB4WLnyZ0+ROwNUY7GhprHtClwLK+pxpKIeOq3GIwDLSnDW2LRVRqWwwn2dQ8003SOitsdAhSgMNDf1I638OeBaorxiTymsdmdr/G+2nXD3UFFcR1r1s/OEGQ4BdEuOQka8/0JZKaMiNX07WtmAclcmZPORSrkXy4q9zqmW4XmJiA5QryEX1NZasLvIc5uLojasU5HqU4bmxHvUjmS6pn6OV7VNoKJshHeoPPjKKyJqewxUiMJAsGJawF2jcriiHlabAz/sLJYf+2VvKY64pmw8MipRntcJlE0B3I3rjrl6qSj3/XEIYMVeZ1Zlpeu/gbIpgCJQMTfKhbSSE20ZqEjTPj09xyJlVI630dTPEcV02GEGKkTtjoEKURiINUXIGxF6BxiAczolxqiH3SGwv7QWPxWUAACiDDo02QU+3lDo81yfQCVAIS0ApMcaoddq0GQXKKmxyPv3SGP6uaAUNrtDrgmZEGRPo9QYZ6BQWmvBHlchrXSdtsqoCCHk/inKQlrAXaNSZG6E3XHyxa/Kuh1O/RC1PwYqRGFAp9XgvnP74vrx+cj0Mz2j0WjkgtpF6wtRVd+EhKgI3DghHwCw25W5UGZUEr16iIwJUEgLAHqdFpmuTERhZb28f8/lw3MAAMv3lOK3o1WoabQhPjICg7PjA15LyqgUm909TkZ0cy6pPt5GdSP7S+tQbLbAoNdieDfP5dppsc4GdnaHaJPiV2ZUiNTFQIUoTNwysScenT4gYNt3qU5l0Xpn9uTsfmm46LQsj3OUNSpRBh0idM5rZcSZkJsUGfT1cxKc0z+Hyuqw7Vg1AOC6Cd0Ra9Kjos4q7w00rmeynCHxRwpUNh+pREOTHQa9Fqe7sjltlVFZsvUEAOd0lilC5/GYTqtBhqtpnRQYVdZZMen5ZXh48bYWvY7DITyWbB8qq+cSZaJ2xkCFqIOQVv40NDn7mpwzIB290mI9dmxWZlQ0Go1cpDs6P6nZfW+kQGZZQQkamxyINerRJy0WZ7qmeX7a7Zxuam6rAGnVj7THUO+0GHlVUaAalbJaCxatP4KyEFr42+wOLFzvbN1/xcgcv+dIWSmpoPbnPSU4VF6PTzYeRZOrCDkUpbUWWGwOaDXOHjW1FptcZExE7YOBClEHIWVUAGdH3DNcAcQFg91ZFe+6FKlIN1h9ikQKJqSAZEhuPLRaDSb19axHOaNX4PoUwJ1RkfTNiJWnlbyXDDc22fHPn/dh0vM/44FPt+HxL3c0O85lBaU4Ud2IpGgDzhvkf4dkqU5F6t2y6XAVAMBqczS7uaOSVJ+SlRApN5Lj9A9R+2KgQtRB9EqLlr8f3zNZXh58wRD3h7V3oHLlyFwMzIoL+IGuJC1RbmxyZhyGuvblmagIVPKSopCXHOXzXKXkGM/amL7psXKGQ5lROVbVgMkvLMdz3xWg1mID4Fx23VwB7PtrDwMArhiRA6Ne5/ccKTA65sqobC6slB/bfszs9zn+SPUpeUlR6JYsTY2xoJaoPTFQIeog8pKi5dqQKQPS5eO90mIxolsi9FoNeqfFejznxjN6YMkdZyAlxjPL4Y+UUZEMdXWdTYs1YVC2c8+cYMuSJUa9ziNg6psRiwxXNqKm0SYHJe+tPoRjVQ3IiDPhhSuGItakh7nRhu2u+hh/CivqsXyPc4n0jNF5Ac9TttGvt9qw64R7mfSO44Gv7/t6zkAnNzEK3ZKdgSIzKkTti4EKUQdh0GsxtX86MuJMOG+gZ4bk7Vmj8MOciXI/lNaQMioSZXv82yb1Qu+0GFw9tpkdC11SFYFRv4w4xBj18h5E0p4/0hLoOVP74LIROTjdtWfQKteyY38+WHcEQjgDpu4p0QHPk6Z+jlc1YuvRao8szQ5FRqXBasfMf6/BX7/e6fc6UkYlNykS3aWMCpcoE7UrBipEHcgbV4/Arw+ejWSvDEl8VETQD+5QpMeZPFYJpce5l0mfPzgT38+ZiH4Zoe1GLNWpxJn0SI9zfq+c/rE7BLYddWY2pMzNeFc/lF/3lfu9ptXmwEeuFU8zxwQPmNyv1YBNrq0ApOXdO0+Y4XAFLssKSrBqXzne+fUQrDbfItvCSilQYUaFSC0MVIg6GG2QpcEnQ6fVyJmIobmB+6SEQlr50y8jTl5tJLW2P1HViP2ltaiz2hFl0Mldd6XVROsPVaCxyXPH5uNVDbjh3fUor7MiPc6Iyf3Tgr5+tus+ymqtWHPAuXP0FSNzYdRrUWux4bArU/Kzq3GezSFwoMy3yLawwh2o5LsCQWZUiNoXAxUikuW66lSGeu2K3FJSTUr/THfNjDKjIrXoH5wdL9fd9EyNQVqsERabA5sOO7MgQgh8tKEQ5760Ar/sLYNRr8Vj0wciQhf8r66EqAiYIpzn/LrPOZU0qnsi+mU6M0I7jldDCOGx4aJ3u3+LzY4is7P4Ny8pCnmuabXqhiZ57yMiOvUYqBCR7MYz8jG5X5rckba1rh7bDTedkY+bzuwhH5M2RCwyN8j1Kco6GI1Ggwm9nFkVqU7lP2sO4/5PtqLGYsOwvAR8c+cZOH9wZrOvr9G4s0M2h0CEToOBWfEYmOUMVLYfM2PHcbNH51qp3b/kWGUDhAAiI3RIjjYg0qCTG8lxc0Ki9uN/+1Mi6pIm9U3DpL7Bp1VCkZ0Qib9cMMDjWFa8u8C1vM4ZIHhnbsb1SsFnm49h5b5yXHxaDf66ZBcA4LZJPXHPOX2DdsT1lhUfiQOlzoBiYFY8TBE6DMpyTmntOF6NGKNzabNW49x4saDIc+qn0NWRNi8pSp6+6pYchSJzIw6X12NYnmfr/lNB6oLbXLM+os6MGRUiahdSRuVweR12u5YLewcq43s5C2q3Ha3C7Pc3wWpzYFLfVNx3bsuCFAAeeyYNdwUV0jLrHcfN8rTPBUOcDfMKij37qyhX/Ei6J0t1Ku2TUXng060Y9tT3bbb1AFFHxECFiNqFFDgcKq+HzSGQEmNEltcGjJnxkeiRGg2HAPaW1CI52oDnLh/SqoyCNPUDAMO7JQAA+qTHQqfVoKLOio2uOpg/uaanCisaUOfq8QIAR12BirK/TLcU5/eH/RTUFlbU42BZ2wUwpTUWfLLxKKrqm7Bib2nzTwjA4RBYsvUEnl+6Gw1We/NPIAoznPohonaRmeDZp2VoTrzfAGR8zxR5yua5y4cgLdZ3N+lQZCX4ZlRMETr0TouRd5vukx6DQdnxSI01orTGgr0ltXLdjLQ0OU/RmyY/QEalpKYR57/yCyw2Bz6/bTwGZIW2jDuY77afgNT+Zefx0LvpShwOgW+3F+EfP+6Rd7FOjDLgxjN6NPNMovDCjAoRtYsYox6xRve/jQKtLLp0eDYMei1umdgTk/un+z0nFNIKpow4k8c00KBs99Lrs1z1OH3TnauTCorcAcERxdJkidRL5VBZnccuyi99vxc1jTZYbQ7ctWizz/Lq1vjqtxPy960JVJ75bjdmf7BJDlIA4LejoXflJQoXDFSIqN1kKAKGQIHKsLxE7HryPDw4rd9Jvdbo/CTcdEY+/va7QR6Zm4GKbIe0j1EfOVBxf6hL7fM9Miop0YiM0KGyvglvLD8AwLlaaJFrN+dYkx57imvx3HcFJzX2E9UNWH+4Qv5Z2aQuFNUNTfjPaueeSLdN6olXZwwDgKDbExCFKwYqRNRulNM/Q3MCN5VraeGsP3qdFn+5YIBPVmaI63VjjHqM7ObcVbpvhrPpnLREuaLOiuqGJgCeWwtEGnR4dLpzNdPzS3dj1b4yzP1mFxwCOG9gBl75gzMgeHvVQfziVVdSb7Xhoc+24YZ31qOkJnhx7JKtJyCEc/m2QedsUne0siHoc5Q+33wMDU129E2PxX3n9sV417Lvg2V1MDc2hXwdonDAQIWI2k2mqw9J9+QoJEQZmjn71Biel4iHz++HV2cMg0Hv/Cuwr2trgAJXoPLJRmer/j7pMfIu1ZI/jMrFlSNz4BDAze9twLKCUui1GjwwrR/O6peGq093tve/48PN+Gh9IewOgWNVDbh83mp8uO4IftxdgiveWC13vfXn663OaZ/fDctGH1cQFepmikIIfLDWmeH545g8aDQaJEUb5G69rZlGIlITAxUiajfSUt/26EESiEajwc1n9sRZ/dz9Ynq72viX1lhQbG7E2ysPAQBunOBbeKrRaPDkxYMwKDsOda5VNFed3k1usf/w+f0xIDMOlfVNuP/TrZj2jxW4+LWV2HnCjORoA3ISI3G4vB6XzfvVpxsu4Fw9tKWwCloNMG1wBgZmOjNAO0+EFmBsPFyJguIamCK0uGRYtnxcWprN6R/qaBioEFG7+f2oPPxpYg/cObm32kPxEG3Uy0HU80sLUGRuRFqsERcPy/J7vilCh3kzRyA52oCUGCPuUNxPpEGHxbPH4f8u6I/4yAjsKa5FWa0V/TPj8OWfJ+DTW8ehb3osSmosuGzer3jp+z3yNBMAfPnbcQDA6T2SkRZrklcQhZoJkbIpFw3NQnxkhHx8sKuIeBsDFepguDyZiNpNaqwRD03rr/Yw/OqbHofCigZ8svEoAOC68fkw6nUBz89NisJP90wC4Ny9Wsmo1+HGM3rgihG5eGvlAdRb7ZhzTh9EGZx/5S760+m46b0NWH+oEv/4cS/eXnUQ43omY/sxM45VOWtRpg91BklSoLIjhEClss6Kr7c5p43+6LXD9EAGKtRBMVAhIoKzoPaHXcUAnIW2fxyT1+xzvAMUf4/POaevz/GEKAMW3TzWo8/J0h3O19ZqgJHdk3DhEOeeRv1dGykWmRtRXmtBcozR41pltRYs2XoC5bUWbD1WDavNgQGZcT7FylJG5WBZHWotNsQY+dc/dQz8k0pEBPcSZQCYMTrXY9rkVNBqNbhgSCamDcrA/3YW42BZHYbkxOO03ASPAt4Yox7dk6NwqLweu07UYEJvd6BSVmvBJa+v8lkRdNXp3Xya6aXEGJEZb8KJ6kbsPG7G6PykU3p/RG2FgQoREdz9VfRaDa6fkN9ur6vVanDeoIyg5wzIisOh8nrsPFGNCb2dS40tNjtu+c9GHK1sQHZCJM7ul4bEaANyEyNxaYDdrwdlx+NEdSO2HasOGqj8uq8Mn2w6ijvO7o3uriJhIrUwUCEiAtArLRZPXTwQqbEmZMZHNv+EdjQgMw7fbCuS61SEEPjL4u3YcLgSsSY93r1+NHq5Vi4FMygrHt/vLA648kcIgXd+PYS/LtkFu0OgtMaC/9wwpk3vhailGKgQEblcPba72kPwa2CWa4nycTPqrTa88L89+GTjUWg1wOt/HB5SkAIAg3MCL1G22hx47Mvt+HBdoXzsl71l2Ha0GoODNOcjOtW4PJmIKMxJK3/2l9bi7L8vx1srDwIAHrlwAM7skxrydaR9jvaX1qLeavN47K9LduLDdYXQaICHz++H37l6sMxbvq8tboGo1RioEBGFubRYI5KjDXAI5+qfnMRIzJs5HNeNb1ktTVqsCelxRjiEZ1+W7ceq8Z81zr2B5s0cjpvP7IlbJ/UEAHy7vQj7S2v9Xk9SZ7Fh8eajqKq3tvDOnKobmrCvpAabjlRi5d4yVNR5XmfZ7hJMeXE55iza4hNgSfaV1OCN5fvx2aajaLI7WjWOU8nc2IQDzbyP5B+nfoiIwpxGo8Elw7Lx8YZC/GliT9wwIR+miMA9XoIZnB2PYnMJ3lp5EMPyEqHVAI9/uQNCABcOycR5g5zLovukx2JK/3T8sKsY85fvx3OXD/V7vVqLDbPeXoeNhysxNDcBn94yFnqd89/Ae4pr8H+fb8fxqgZYbA44HAK3TuqJG89wd/xdvb8c17y9Fk1296aLpggtfj8yFzNP74YFqw7hw3XOJnb7Smqxq6gGb14zAjmJUThW1YCvfjuOL7Ycxy5F594Xv9+D2Wf1wmXDc+RtEtTkcAhc/dY6bD9WjYU3n45R3bniqiU0QrlXeQdjNpsRHx+P6upqxMXFNf8EIqIOTAjhs+y4pdYcKMfVbzkDgz+OycOo7om4e9FviIzQ4ad7J3oUEm86UolL//krInQa/DBnIrole64AqrPYcO2CdVh/qFI+9sB5/XDrpJ6orm/C9NdW4ojXnkY6rQaLbxuHITkJqLfacO7LK1BY0YAYox4Jrr40/jZg/P3IXPy4uxhltVYkRxuQnxKNDYfdr6vXajCuVwp2Hq9GWa0zIzM4Ox4f3ny6R8+YPcU10Go0Idf1tIX/7SjCzf/ZCAAY3ysZ7994eru99slqiz9z/rTk85uBChFRF7Nk6wnc/uEmCAEYdFpY7Q7cd25fzD6rl8+5v5+/GmsPVkCn1WBMfhKmDkhHnCkCTXYHPtt0DOsOVSDWpMeM0Xn414oDMOi0+PLP4/H8dwX4cXcJchIj8dLvT0O0QY/Xl+3Dkm0n0CstBl//eQKe+64Ab686iKx4E5befSZiTREQQuDX/eWY9/N+rNxXhuyESDx/xRCM65mCY1UNuPm9DfLqJ40GGJOfhIuGZmPaoAwkRhvQYLXj/bWH8dqyfaiqb8LZ/dLw5jUjodNq8PGGQjzw6VY4hHOLgXvO6SMHXza7A1qNBto22LlbSQiBC19d6dFZ+JNbxmJkB8iqlJgbceN7G/D4RQMxvI335+pwgcrrr7+O559/HkVFRRg6dCheffVVjB49utnnMVAhImqdD9cdwUOfbQMAdEuOwv/uPtPvlgH7Smox56Mt2HrU/5LmWKMe/7lxDIbmxOOGdzfgp90liDXpUdNog0GvxWe3jpOLeCvrrDjn5RUorbHg7H5pWFZQAiGAd64bhUl903yuXVhRj9RYo8c0V4PVjjeW70esSY8Lh2QhI97kd1xbCqvw+/mrYbE5cP34fOQkRuLJr3d6nKPXatA/Mw4lNY0orbEg1hSByf3ScO6gDJzZOxWRhtZNryn9uKsYN7y7AVEGHSb2ScW324twRu+UNl/2faK6AesOVmBK/3SfHb9bo95qw+/nr8G2Y9XonxmHJX+e0KZBXIcKVBYtWoRrrrkGb7zxBsaMGYOXX34ZH3/8MQoKCpCW5vsHV4mBChFR67376yG8t/oQnv7dYIzpkRz03CPl9fh2+wmsPlAOhwAitBrEmPS46YweciBSbG7E1BeXw9zoLHh97vIhuHJkrsd1pA9uyWXDc/DClf7rX07Wkq0nMPuDTR7HbpyQj0uGZeO5pQVYsac04HP1Wg0GZMVheF4iuidHyccTow0Y1T0JWQnN99oRQuCS11fht6PV+NPEHrhqTDdM+vvPsDsEPrttnEeWos5iw1srD2LncTPO7peGC4dmyntDKVU3NOFweR3ykqKQEGVArcWG+cv3481fDqCxyYFeaTH458zhHp2WW8ruEPjTfzbgh10lSIo24LNbx7V5478OFaiMGTMGo0aNwmuvvQYAcDgcyM3NxZ///Gc8+OCDQZ/LQIWIKLx89dtx3LlwM64+vRueuHiQ33Pu/+Q3fLThKFJijPhhzplIiDKcsvG8vmwfnl9aAAC4Z2of3H52L7nmYkthFYqqG5GVYEJGvAmHyuqxdEcRvtteJG8OGUheUhRGdkvEgKw49MuIQ05iJLRetRybCytx58ItMEVosfKBs5ESY8R9H/+GjzcexZl9UvG3S5zvz4q9pXjp+70oq7XIz4016XHewAwkxxhhitCizmLDmgMV2H68GtKndkqMEXaHA5X1zt23DXotrDYHIiN0ePyiARiT7w4+lUPTQOP3uOTNXw7gvdWHYdBr8eFNp2NEt7ad9gE6UKBitVoRFRWFTz75BJdccol8fNasWaiqqsIXX3zhcb7FYoHF4v5Fms1m5ObmMlAhIgojtRYbog26gEWYdRYb/rXiACb3T8OQnIRTOhYhBD7ecBTxURE4d2DwrQqUzzla2YBNRyqx+UgVSmoa5Xs5WlGP7cfNsDtC/+i8cUI+/u/CAQCAQ2V1OPuFn+Hv6d2SozBtUCaWbDuOworAgVJytAHliiXc3ZOj8OC0fhjZPQl3LdyClfvKQh5bMK//cTgucG2O2dZaEqioujy5rKwMdrsd6enpHsfT09Oxe/dun/Pnzp2LJ554or2GR0RErdDczszRRj3untqnXcai0Whw5ajc5k/0ek5uUhRyk6Jw8WnZPo/XWmzYcKgCW49WY3eRGbtO1KDE3Oj3WtmJkfjTxJ7yz91TonHLxJ54b/VhOFx5goTICNx0Zg/MHNMNBr0W95/bFyv3lWHtwXI0WB2w2OzQajQY0S0RY3smIz3OhFqLDftLalHd0ITTeyTLy7DfvX40Xl+2D+/+eggWm7OfjDIfoYyPlGkKAeXycB3umdrnlAUpLaVqRuX48ePIzs7Gr7/+irFjx8rH77//fixfvhxr1671OJ8ZFSIioo6vw2RUUlJSoNPpUFxc7HG8uLgYGRm+KTqj0Qij0ehznIiIiDonVVv2GQwGjBgxAj/++KN8zOFw4Mcff/TIsBAREVHXpHoL/Tlz5mDWrFkYOXIkRo8ejZdffhl1dXW47rrr1B4aERERqUz1QOX3v/89SktL8eijj6KoqAinnXYavvvuO58CWyIiIup6VO+jcjLYR4WIiKjjacnnt/rbShIREREFwECFiIiIwhYDFSIiIgpbDFSIiIgobDFQISIiorDFQIWIiIjCFgMVIiIiClsMVIiIiChsMVAhIiKisKV6C/2TITXVNZvNKo+EiIiIQiV9bofSHL9DByo1NTUAgNzcXJVHQkRERC1VU1OD+Pj4oOd06L1+HA4Hjh8/jtjYWGg0mja9ttlsRm5uLgoLC7vEPkJd7X6BrnfPXe1+ga53z13tfoGud8+d5X6FEKipqUFWVha02uBVKB06o6LVapGTk3NKXyMuLq5D/2Foqa52v0DXu+eudr9A17vnrna/QNe7585wv81lUiQspiUiIqKwxUCFiIiIwhYDlQCMRiMee+wxGI1GtYfSLrra/QJd75672v0CXe+eu9r9Al3vnrva/QIdvJiWiIiIOjdmVIiIiChsMVAhIiKisMVAhYiIiMIWAxUiIiIKWwxU/Hj99dfRvXt3mEwmjBkzBuvWrVN7SG1i7ty5GDVqFGJjY5GWloZLLrkEBQUFHuc0NjZi9uzZSE5ORkxMDC677DIUFxerNOK298wzz0Cj0eCuu+6Sj3W2ez527BiuuuoqJCcnIzIyEoMHD8aGDRvkx4UQePTRR5GZmYnIyEhMmTIFe/fuVXHEJ8dut+ORRx5Bfn4+IiMj0bNnTzz11FMee4h09HtesWIFpk+fjqysLGg0Gnz++ecej4dyfxUVFZg5cybi4uKQkJCAG264AbW1te14F6ELdr9NTU144IEHMHjwYERHRyMrKwvXXHMNjh8/7nGNjnS/QPO/Y6VbbrkFGo0GL7/8ssfxjnbPoWKg4mXRokWYM2cOHnvsMWzatAlDhw7Fueeei5KSErWHdtKWL1+O2bNnY82aNfj+++/R1NSEc845B3V1dfI5d999N7766it8/PHHWL58OY4fP45LL71UxVG3nfXr12P+/PkYMmSIx/HOdM+VlZUYP348IiIi8O2332Lnzp144YUXkJiYKJ/z3HPP4ZVXXsEbb7yBtWvXIjo6Gueeey4aGxtVHHnrPfvss5g3bx5ee+017Nq1C88++yyee+45vPrqq/I5Hf2e6+rqMHToULz++ut+Hw/l/mbOnIkdO3bg+++/x9dff40VK1bg5ptvbq9baJFg91tfX49NmzbhkUcewaZNm/DZZ5+hoKAAF110kcd5Hel+geZ/x5LFixdjzZo1yMrK8nmso91zyAR5GD16tJg9e7b8s91uF1lZWWLu3LkqjurUKCkpEQDE8uXLhRBCVFVViYiICPHxxx/L5+zatUsAEKtXr1ZrmG2ipqZG9O7dW3z//fdi4sSJ4s477xRCdL57fuCBB8SECRMCPu5wOERGRoZ4/vnn5WNVVVXCaDSKDz/8sD2G2OYuuOACcf3113scu/TSS8XMmTOFEJ3vngGIxYsXyz+Hcn87d+4UAMT69evlc7799luh0WjEsWPH2m3sreF9v/6sW7dOABCHDx8WQnTs+xUi8D0fPXpUZGdni+3bt4tu3bqJl156SX6so99zMMyoKFitVmzcuBFTpkyRj2m1WkyZMgWrV69WcWSnRnV1NQAgKSkJALBx40Y0NTV53H+/fv2Ql5fX4e9/9uzZuOCCCzzuDeh89/zll19i5MiRuOKKK5CWloZhw4bhzTfflB8/ePAgioqKPO43Pj4eY8aM6ZD3CwDjxo3Djz/+iD179gAAfvvtN6xcuRLTpk0D0DnvWSmU+1u9ejUSEhIwcuRI+ZwpU6ZAq9Vi7dq17T7mtlZdXQ2NRoOEhAQAnfN+HQ4Hrr76atx3330YOHCgz+Od8Z4lHXpTwrZWVlYGu92O9PR0j+Pp6enYvXu3SqM6NRwOB+666y6MHz8egwYNAgAUFRXBYDDI/7NL0tPTUVRUpMIo28bChQuxadMmrF+/3uexznbPBw4cwLx58zBnzhw8/PDDWL9+Pe644w4YDAbMmjVLvid/f8Y74v0CwIMPPgiz2Yx+/fpBp9PBbrfjb3/7G2bOnAkAnfKelUK5v6KiIqSlpXk8rtfrkZSU1OHfg8bGRjzwwAOYMWOGvElfZ7zfZ599Fnq9HnfccYffxzvjPUsYqHRRs2fPxvbt27Fy5Uq1h3JKFRYW4s4778T3338Pk8mk9nBOOYfDgZEjR+Lpp58GAAwbNgzbt2/HG2+8gVmzZqk8ulPjo48+wvvvv48PPvgAAwcOxJYtW3DXXXchKyur094zOTU1NeHKK6+EEALz5s1TezinzMaNG/GPf/wDmzZtgkajUXs47Y5TPwopKSnQ6XQ+Kz6Ki4uRkZGh0qja3u23346vv/4ay5YtQ05Ojnw8IyMDVqsVVVVVHud35PvfuHEjSkpKMHz4cOj1euj1eixfvhyvvPIK9Ho90tPTO9U9Z2ZmYsCAAR7H+vfvjyNHjgCAfE+d6c/4fffdhwcffBB/+MMfMHjwYFx99dW4++67MXfuXACd856VQrm/jIwMnwUBNpsNFRUVHfY9kIKUw4cP4/vvv5ezKUDnu99ffvkFJSUlyMvLk/8eO3z4MO655x50794dQOe7ZyUGKgoGgwEjRozAjz/+KB9zOBz48ccfMXbsWBVH1jaEELj99tuxePFi/PTTT8jPz/d4fMSIEYiIiPC4/4KCAhw5cqTD3v/kyZOxbds2bNmyRf4aOXIkZs6cKX/fme55/PjxPkvO9+zZg27dugEA8vPzkZGR4XG/ZrMZa9eu7ZD3CzhXgWi1nn+V6XQ6OBwOAJ3znpVCub+xY8eiqqoKGzdulM/56aef4HA4MGbMmHYf88mSgpS9e/fihx9+QHJyssfjne1+r776amzdutXj77GsrCzcd999WLp0KYDOd88e1K7mDTcLFy4URqNRvPPOO2Lnzp3i5ptvFgkJCaKoqEjtoZ20W2+9VcTHx4uff/5ZnDhxQv6qr6+Xz7nllltEXl6e+Omnn8SGDRvE2LFjxdixY1UcddtTrvoRonPd87p164Rerxd/+9vfxN69e8X7778voqKixH//+1/5nGeeeUYkJCSIL774QmzdulVcfPHFIj8/XzQ0NKg48tabNWuWyM7OFl9//bU4ePCg+Oyzz0RKSoq4//775XM6+j3X1NSIzZs3i82bNwsA4sUXXxSbN2+WV7mEcn/nnXeeGDZsmFi7dq1YuXKl6N27t5gxY4ZatxRUsPu1Wq3ioosuEjk5OWLLli0ef5dZLBb5Gh3pfoVo/nfszXvVjxAd755DxUDFj1dffVXk5eUJg8EgRo8eLdasWaP2kNoEAL9fCxYskM9paGgQt912m0hMTBRRUVHid7/7nThx4oR6gz4FvAOVznbPX331lRg0aJAwGo2iX79+4l//+pfH4w6HQzzyyCMiPT1dGI1GMXnyZFFQUKDSaE+e2WwWd955p8jLyxMmk0n06NFD/OUvf/H40Oro97xs2TK//+/OmjVLCBHa/ZWXl4sZM2aImJgYERcXJ6677jpRU1Ojwt00L9j9Hjx4MODfZcuWLZOv0ZHuV4jmf8fe/AUqHe2eQ6URQtG+kYiIiCiMsEaFiIiIwhYDFSIiIgpbDFSIiIgobDFQISIiorDFQIWIiIjCFgMVIiIiClsMVIiIiChsMVAhok7l559/hkaj8dm/iYg6JgYqREREFLYYqBAREVHYYqBCRG3K4XBg7ty5yM/PR2RkJIYOHYpPPvkEgHtaZsmSJRgyZAhMJhNOP/10bN++3eMan376KQYOHAij0Yju3bvjhRde8HjcYrHggQceQG5uLoxGI3r16oW33nrL45yNGzdi5MiRiIqKwrhx43x2lSaijoGBChG1qblz5+K9997DG2+8gR07duDuu+/GVVddheXLl8vn3HfffXjhhRewfv16pKamYvr06WhqagLgDDCuvPJK/OEPf8C2bdvw+OOP45FHHsE777wjP/+aa67Bhx9+iFdeeQW7du3C/PnzERMT4zGOv/zlL3jhhRewYcMG6PV6XH/99e1y/0TUxtTeFZGIOo/GxkYRFRUlfv31V4/jN9xwg5gxY4a8Q+zChQvlx8rLy0VkZKRYtGiREEKIP/7xj2Lq1Kkez7/vvvvEgAEDhBBCFBQUCADi+++/9zsG6TV++OEH+diSJUsEANHQ0NAm90lE7YcZFSJqM/v27UN9fT2mTp2KmJgY+eu9997D/v375fPGjh0rf5+UlIS+ffti165dAIBdu3Zh/PjxHtcdP3489u7dC7vdji1btkCn02HixIlBxzJkyBD5+8zMTABASUnJSd8jEbUvvdoDIKLOo7a2FgCwZMkSZGdnezxmNBo9gpXWioyMDOm8iIgI+XuNRgPAWT9DRB0LMypE1GYGDBgAo9GII0eOoFevXh5fubm58nlr1qyRv6+srMSePXvQv39/AED//v2xatUqj+uuWrUKffr0gU6nw+DBg+FwODxqXoio82JGhYjaTGxsLO69917cfffdcDgcmDBhAqqrq7Fq1SrExcWhW7duAIAnn3wSycnJSE9Px1/+8hekpKTgkksuAQDcc889GDVqFJ566in8/ve/x+rVq/Haa6/hn//8JwCge/fumDVrFq6//nq88sorGDp0KA4fPoySkhJceeWVat06EZ0iDFSIqE099dRTSE1Nxdy5c3HgwAEkJCRg+PDhePjhh+Wpl2eeeQZ33nkn9u7di9NOOw1fffUVDAYDAGD48OH46KOP8Oijj+Kpp55CZmYmnnzySVx77bXya8ybNw8PP/wwbrvtNpSXlyMvLw8PP/ywGrdLRKeYRggh1B4EEXUNP//8M8466yxUVlYiISFB7eEQUQfAGhUiIiIKWwxUiIiIKGxx6oeIiIjCFjMqREREFLYYqBAREVHYYqBCREREYYuBChEREYUtBipEREQUthioEBERUdhioEJERERhi4EKERERhS0GKkRERBS2/h+Uc5KyQwXPgAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model mean square error')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig('../models/model_training.png')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "588026dc0a0693bc2e2f2499b6a59c0628249da82b6c68440ef2bcf57754a22d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
